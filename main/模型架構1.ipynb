{"cells":[{"cell_type":"markdown","source":["# 能運作"],"metadata":{"id":"TStozTH0dqO6"}},{"cell_type":"markdown","source":["## 此 install 是用來debug的。install 過後，要重新啟動工作階段才能運行成功"],"metadata":{"id":"5PfxbMB3ekHb"}},{"cell_type":"code","source":["!pip install accelerate==0.23.0"],"metadata":{"id":"D0S-Oj7Wd8_b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 使用 wandb 繪製訓練圖"],"metadata":{"id":"phVPv-2IkrZz"}},{"cell_type":"code","source":["!pip install wandb\n","%env WANDB_LOG_MODEL=true\n","import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7va1swHnigCE","executionInfo":{"status":"ok","timestamp":1703316199549,"user_tz":-480,"elapsed":425,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"9cf33cad-ff22-4e23-dadd-14e49b9888eb"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnrnmnrn\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"stream","name":"stdout","text":["env: WANDB_LOG_MODEL=true\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## 載入資料"],"metadata":{"id":"Hk6kR7vMk5Ii"}},{"cell_type":"code","source":["#載入資料\n","import pandas as pd\n","import torch\n","input_20_songs_sequence = ['song_id_13 song_id_16 song_id_17 song_id_6 song_id_17 song_id_2 song_id_17 song_id_14 song_id_13 song_id_2 song_id_11 song_id_18 song_id_13 song_id_12 song_id_16 song_id_1 song_id_6 song_id_15 song_id_10 song_id_16', 'song_id_18 song_id_19 song_id_5 song_id_7 song_id_17 song_id_12 song_id_6 song_id_15 song_id_19 song_id_1 song_id_20 song_id_19 song_id_17 song_id_19 song_id_19 song_id_8 song_id_8 song_id_5 song_id_3 song_id_7']\n","output_5_songs_sequence = ['song_id_7 song_id_12 song_id_18 song_id_5 song_id_18', 'song_id_6 song_id_19 song_id_8 song_id_15 song_id_14']\n","data = {'input_20_songs_sequence': input_20_songs_sequence, 'output_5_songs_sequence': output_5_songs_sequence}\n","df = pd.DataFrame(data)\n","song_to_int = {f'song_id_{i}': i+1 for i in range(21)}\n","int_to_song = {i+1: f'song_id_{i+1}' for i in range(21)}\n","int_to_song[0] = '[PAD]'"],"metadata":{"id":"syVj1f00j0m5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 描述"],"metadata":{"id":"3ez2odk8k7JR"}},{"cell_type":"code","source":["#使用Huggingface的生成式模型，並訓練模型\n","#輸入為使用者聽的前20首歌，預測接下來會聽的5首歌\n","#預測的5首歌都要不同。若預測的5首歌有重複，則視為預測錯誤\n","#輸入的20首歌中，有可能有重複的歌曲"],"metadata":{"id":"WWCjnNEkj3JY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 載入模型"],"metadata":{"id":"jTMmWamjk-UU"}},{"cell_type":"code","source":["#載入模型\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"],"metadata":{"id":"Mq2YxA2Hj5IP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 載入訓練資料"],"metadata":{"id":"-9Tq4e-8lBHK"}},{"cell_type":"code","source":["#載入訓練資料\n","from torch.utils.data import Dataset\n","\n","class SongDataset(Dataset):\n","    def __init__(self, df, tokenizer, song_to_int):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        self.song_to_int = song_to_int\n","        self.max_len = 25\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        input_20_songs_sequence = self.df.iloc[idx]['input_20_songs_sequence']\n","        output_5_songs_sequence = self.df.iloc[idx]['output_5_songs_sequence']\n","        input_20_songs_sequence = [self.song_to_int[song] for song in input_20_songs_sequence.split(' ')]\n","        output_5_songs_sequence = [self.song_to_int[song] for song in output_5_songs_sequence.split(' ')]\n","        input_20_songs_sequence = [0] + input_20_songs_sequence\n","        output_5_songs_sequence = [0] + output_5_songs_sequence\n","        input_20_songs_sequence = input_20_songs_sequence + [0] * (self.max_len - len(input_20_songs_sequence))\n","        output_5_songs_sequence = output_5_songs_sequence + [0] * (self.max_len - len(output_5_songs_sequence))\n","        input_20_songs_sequence = torch.tensor(input_20_songs_sequence)\n","        output_5_songs_sequence = torch.tensor(output_5_songs_sequence)\n","        return input_20_songs_sequence, output_5_songs_sequence\n","\n","train_dataset = SongDataset(df, tokenizer, song_to_int)"],"metadata":{"id":"xR7oOt1wj7hc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 訓練模型\n"],"metadata":{"id":"OJ1TIzAElEOn"}},{"cell_type":"code","source":["#訓練模型\n","from transformers import Trainer, TrainingArguments\n","from transformers import default_data_collator\n","\n","def my_data_collator(features):\n","    # Your custom data collation logic here\n","    input_20_songs_sequence, output_5_songs_sequence = zip(*features)\n","\n","    # Padding sequences to the maximum length\n","    input_20_songs_sequence = torch.nn.utils.rnn.pad_sequence(input_20_songs_sequence, batch_first=True, padding_value=0)\n","    output_5_songs_sequence = torch.nn.utils.rnn.pad_sequence(output_5_songs_sequence, batch_first=True, padding_value=0)\n","\n","    return {\n","        'input_ids': input_20_songs_sequence,  # Rename to 'input_ids'\n","        'labels': output_5_songs_sequence,  # Rename to 'labels'\n","    }\n","\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=1,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_steps=500,\n","    save_total_limit=1,\n","    evaluation_strategy='steps',\n","    eval_steps=500,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='eval_loss',\n","    greater_is_better=False,\n","    report_to=\"wandb\"\n",")\n","\n","# Update the Trainer instantiation to include the callback\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    data_collator=my_data_collator,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":566},"id":"yMus1Muoj-H3","executionInfo":{"status":"error","timestamp":1703335754429,"user_tz":-480,"elapsed":24755,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"63927e23-89f3-4c7a-d7f3-5bcb8102e20d"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6ffe3dab3171>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memo...\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"npu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"xpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \"\"\"\n\u001b[1;32m   1886\u001b[0m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1887\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m_setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.20.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   1788\u001b[0m                     \u001b[0;34m\"Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 )\n","\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["## 使用範例"],"metadata":{"id":"Nq3cVcLdlGBw"}},{"cell_type":"code","source":["input_20_songs = 'song_id_13 song_id_16 song_id_17 song_id_6 song_id_17 song_id_2 song_id_17 song_id_14 song_id_13 song_id_2 song_id_11 song_id_18 song_id_13 song_id_12 song_id_16 song_id_1 song_id_6 song_id_15 song_id_10 song_id_16' #20首歌\n","input_20_songs = [song_to_int[song] for song in input_20_songs.split(' ')]\n","input_20_songs = torch.tensor(input_20_songs)\n","input_20_songs = input_20_songs.unsqueeze(0)\n","input_20_songs = input_20_songs.to(model.device)\n","\n","output_5_songs = model.generate(input_ids=input_20_songs, max_length=25, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n","output_5_songs = output_5_songs.tolist()[0][:5]\n","output_5_songs = [int_to_song[song] for song in output_5_songs]\n","print(output_5_songs)"],"metadata":{"id":"bEto1f6Ndox6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# 底下為測試用"],"metadata":{"id":"EN_qfAOhdlNK"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class SongRecommendationModel(nn.Module):\n","    def __init__(self, input_size, output_size, hidden_size, num_layers=2):\n","        super(SongRecommendationModel, self).__init__()\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=hidden_size, nhead=1), num_layers=num_layers)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, src):\n","        src_embedded = self.embedding(src)\n","        src_embedded = src_embedded.permute(1, 0, 2)  # Change the sequence length and batch size dimensions\n","        output = self.transformer(src_embedded)\n","        output = self.fc(output[-1, :, :])  # Take the output of the last time step\n","        return output\n","\n","\n","\n","# 將字符串映射到整數\n","song_id_mapping = {}\n","reverse_song_id_mapping = {}\n","unique_songs = set()\n","\n","def map_songs(data):\n","    for row in data:\n","        for song_id in row:\n","            if song_id not in unique_songs:\n","                unique_songs.add(song_id)\n","                idx = len(unique_songs) - 1\n","                song_id_mapping[song_id] = idx\n","                reverse_song_id_mapping[idx] = song_id\n","\n","input_data = [['6027767fad949f3ca5e772df04924949', '041547bddb0a3e730f32db84c65868ca',\n","               '041547bddb0a3e730f32db84c65868ca', '041547bddb0a3e730f32db84c65868ca',\n","               '8b32f88104ecf859be934d9b45f30cd1', 'e4a125e3163e4c1bd40060614c79bd53',\n","               '8b32f88104ecf859be934d9b45f30cd1', '5ef6718f4517d2d3c316fc45226f41dc',\n","               'e4a125e3163e4c1bd40060614c79bd53', '041547bddb0a3e730f32db84c65868ca',\n","               'e7efab54028017e35a35d1b1637e210c', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","               '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","               '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","               'a97177f0f37a2bae91d8e67831949392', '6027767fad949f3ca5e772df04924949',\n","               '6027767fad949f3ca5e772df04924949', '6027767fad949f3ca5e772df04924949'],\n","              ['883d4ffa999d2f7c8f5293d85112da49', '883d4ffa999d2f7c8f5293d85112da49',\n","               '883d4ffa999d2f7c8f5293d85112da49', 'ecfed150865a7129690805286222656d',\n","               'd36c6cf30154e18e6c972704206d6b1e', 'd36c6cf30154e18e6c972704206d6b1e',\n","               'c7170f4c6488a8f9013f0e4eadf9b385', 'c7170f4c6488a8f9013f0e4eadf9b385',\n","               '940d87a98fef6e456a3f59ecd7e88f63', '883d4ffa999d2f7c8f5293d85112da49',\n","               'f6407930f4a8e921df43911dad3847a3', '4917c1184063708092051859415be029',\n","               '3419b303ba51124a091cde496c6a0c16', 'f57c28ff61e365a82c7a00267d21c96e',\n","               '0d488acd5aa820a96e84f9488f03e335', '807653562fa6eb36cf75dee0279fb124',\n","               '33441a5f6fb494f0d0021f2585c91305', 'fb9b6b981cc1996542d5d81d47b459af',\n","               '65719c6edaa80d0880940c0e20c5e499', '7c4bd89cc6d7c6c91a38d58c2808b1b9']]\n","\n","map_songs(input_data)\n","\n","# 將字符串轉換為整數標識符\n","input_data = [[song_id_mapping[song_id] for song_id in row] for row in input_data]\n","\n","# 將輸出的字符串轉換為整數標識符\n","output_data = [['75c2aa348888f982d85e3f870e6ba5b2', '0cab8863e5440551c7b37e59635ec18e',\n","                '4d5aceee5c9731151ca69f0946ffa71f', '929b07d69451684f4f0f6e3bcc2a62d6',\n","                '12ae4e616d3e5c7bd53ec771797f596b'],\n","               ['34f1a786e245f2886ab99b0062de906c', 'd8ec0f80ee6b4457f12e74aa469335d6',\n","                'd63dbd5214a39f50100c8d59f1c24d6a', 'c1550c264fb083b3acffe619bd02d75e',\n","                '61a3b37f326394081b95196a5eb676b8']]\n","map_songs(output_data)\n","\n","# 將輸出的字符串轉換為整數標識符\n","output_data = [[song_id_mapping[song_id] for song_id in row] for row in output_data]\n","\n","output_size = 5\n","hidden_size = 128\n","num_layers = 2\n","\n","# 初始化模型\n","model = SongRecommendationModel(input_size=len(unique_songs),\n","                                output_size=output_size,\n","                                hidden_size=hidden_size,\n","                                num_layers=num_layers)\n","\n","# 定義損失函數和優化器\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 將你提供的input和output轉換成PyTorch的tensor\n","input_data = torch.tensor(input_data, dtype=torch.long)\n","output_data = torch.tensor(output_data, dtype=torch.long)\n","\n","# 訓練模型\n","num_epochs = 1000\n","for epoch in range(num_epochs):\n","    # 正向傳播\n","    outputs = model(input_data)\n","    loss = criterion(outputs, output_data.view(-1))  # Flatten the output_data tensor\n","\n","    # 反向傳播和優化\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 100 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# 測試模型\n","test_input = torch.tensor(input_data, dtype=torch.long)\n","with torch.no_grad():\n","    model.eval()\n","    predicted_output = model(test_input)\n","    _, predicted_indices = torch.topk(predicted_output, output_size, dim=1)\n","\n","# 將預測的索引轉換為歌曲ID\n","predicted_song_ids = [[reverse_song_id_mapping[idx] for idx in row] for row in predicted_indices.numpy()]\n","\n","# 打印輸出\n","print(\"Predicted Song IDs:\")\n","print(predicted_song_ids)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"tly_Wx5WyAJy","executionInfo":{"status":"error","timestamp":1703068707437,"user_tz":-480,"elapsed":496,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"8d085b3f-6ba0-4f4b-eb9c-f440bfea0ec4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-62222c65172a>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# 正向傳播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Flatten the output_data tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# 反向傳播和優化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (2) to match target batch_size (10)."]}]},{"cell_type":"code","source":["# 使用模型進行預測\n","input_test = [['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T']]\n","input_test_indices = torch.tensor([convert_songs_to_indices(songs, {song: i for i, song in enumerate(total_song)}) for songs in input_test])\n","input_test_indices = input_test_indices.squeeze(0)  # 移除批次維度\n","output_logits = model(input_test_indices)\n","\n","# 將預測轉換為歌曲\n","output_indices = output_logits.argmax(dim=-1).tolist()\n","output_songs = [total_song[idx] for idx in output_indices]\n","print(output_songs)\n"],"metadata":{"id":"bQ-1JmI4-Iib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define the Transformer model\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(TransformerModel, self).__init__()\n","\n","        # Assuming the input and output embeddings have the same size\n","        embed_size = 128\n","        self.embedding = nn.Embedding(input_size, embed_size)\n","        self.transformer = nn.Transformer(\n","            d_model=embed_size,\n","            nhead=2,\n","            num_encoder_layers=2,\n","            num_decoder_layers=2\n","        )\n","        self.fc = nn.Linear(embed_size, output_size)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = x.permute(1, 0, 2)  # Change the shape to (seq_len, batch_size, embed_size)\n","        output = self.transformer(x, x)\n","        output = self.fc(output[-1, :, :])  # Take the last layer's output for classification\n","        return output\n","\n","total_song = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2', 'I2', 'J2', 'K2', 'L2', 'M2', 'N2', 'O2', 'P2', 'Q2', 'R2', 'S2', 'T2','U2','V2','W2','X2','Y2']\n","# Convert song names to indices\n","def song_to_index(song_names):\n","    return [total_song.index(song) for song in total_song]\n","\n","# Example usage\n","input_data = [['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T'],['A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2', 'I2', 'J2', 'K2', 'L2', 'M2', 'N2', 'O2', 'P2', 'Q2', 'R2', 'S2', 'T2']]\n","label_data = [['U', 'V', 'W', 'X', 'Y'], ['U2', 'V2', 'W2', 'X2', 'Y2']]\n","input_size = 200\n","output_size = 5\n","\n","# Create the model\n","model = TransformerModel(input_size, output_size)\n","\n","# Convert input and label to indices\n","input_data = [song_to_index(input_list) for input_list in input_data]\n","label_data = [song_to_index(label_list) for label_list in label_data]\n","\n","input_tensor = torch.tensor(input_data).unsqueeze(0)  # Add batch dimension\n","label_tensor = torch.tensor(label_data).unsqueeze(0)  # Add batch dimension\n","\n","# Define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","epochs = 1\n","for epoch in range(epochs):\n","    # Forward pass\n","    output = model(input_tensor)\n","    loss = criterion(output, label_tensor)\n","\n","    # Backward pass and optimization\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item()}')\n","\n","# Test the model\n","model.eval()\n","with torch.no_grad():\n","    test_input = torch.tensor(song_to_index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T'], total_song)).unsqueeze(0)\n","    output = model(test_input)\n","    _, predicted = torch.max(output, 1)\n","    predicted_songs = [total_song[idx] for idx in predicted.tolist()[0]]\n","    print(f'Predicted songs: {predicted_songs}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":464},"id":"krfLDXVZSwvo","executionInfo":{"status":"error","timestamp":1703123490962,"user_tz":-480,"elapsed":523,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"230ebdf8-db8c-40f8-f586-61b73061e8d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-6affebfa680b>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-6affebfa680b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Change the shape to (seq_len, batch_size, embed_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Take the last layer's output for classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define the Transformer model\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(TransformerModel, self).__init__()\n","\n","        # Assuming the input and output embeddings have the same size\n","        embed_size = 128\n","        self.embedding = nn.Embedding(input_size, embed_size)\n","        self.transformer = nn.Transformer(\n","            d_model=embed_size,\n","            nhead=2,\n","            num_encoder_layers=2,\n","            num_decoder_layers=2\n","        )\n","        self.fc = nn.Linear(embed_size, output_size)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = x.permute(1, 0, 2)  # Change the shape to (seq_len, batch_size, embed_size)\n","        output = self.transformer(x, x)\n","        output = self.fc(output[-1, :, :])  # Take the last layer's output for classification\n","        return output\n","\n","total_songs = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2', 'I2', 'J2', 'K2', 'L2', 'M2', 'N2', 'O2', 'P2', 'Q2', 'R2', 'S2', 'T2','U2','V2','W2','X2','Y2']\n","# Convert song names to indices\n","def song_to_index(song_names, total_songs):\n","    return [total_songs.index(song) for song in song_names]\n","\n","# Example usage\n","input_data = [['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T'],['A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2', 'I2', 'J2', 'K2', 'L2', 'M2', 'N2', 'O2', 'P2', 'Q2', 'R2', 'S2', 'T2']]\n","label_data = [['U', 'V', 'W', 'X', 'Y'], ['U2', 'V2', 'W2', 'X2', 'Y2']]\n","input_size = len(total_songs)\n","output_size = 5\n","\n","# Create the model\n","model = TransformerModel(input_size, output_size)\n","\n","# Convert input and label to indices\n","input_data = [song_to_index(input_list, total_songs) for input_list in input_data]\n","label_data = [song_to_index(label_list, total_songs) for label_list in label_data]\n","\n","input_tensor = torch.tensor(input_data).unsqueeze(0)  # Add batch dimension\n","label_tensor = torch.tensor(label_data).squeeze()  # Remove the batch dimension from labels\n","\n","# Define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    # Forward pass\n","    output = model(input_tensor)\n","    loss = criterion(output, label_tensor)\n","\n","    # Backward pass and optimization\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 1 == 0:\n","        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item()}')\n","\n","# Test the model\n","model.eval()\n","with torch.no_grad():\n","    test_input = torch.tensor(song_to_index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T'], total_songs)).unsqueeze(0)\n","    output = model(test_input)\n","    _, predicted = torch.max(output, 1)\n","    predicted_songs = [total_songs[idx] for idx in predicted.tolist()]\n","    print(f'Predicted songs: {predicted_songs}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410},"id":"Fy3dLHrsDTRx","executionInfo":{"status":"error","timestamp":1703123172917,"user_tz":-480,"elapsed":857,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"6d15acc7-eea8-4814-edb7-3a5a816d7dbd"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-0625ba678736>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-0625ba678736>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Change the shape to (seq_len, batch_size, embed_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Take the last layer's output for classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel, BertTokenizer, BertConfig\n","\n","# 定義BERT模型\n","class MyBertModel(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(MyBertModel, self).__init__()\n","        self.bert = BertModel(\n","            BertConfig(\n","                vocab_size=input_size,\n","                hidden_size=768,  # You can adjust the hidden size as needed\n","                num_hidden_layers=12,  # You can adjust the number of layers as needed\n","                num_attention_heads=12,  # You can adjust the number of attention heads as needed\n","                intermediate_size=3072,  # You can adjust the intermediate size as needed\n","            )\n","        )\n","        self.fc = nn.Linear(768, output_size)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        logits = self.fc(outputs.pooler_output)\n","        return logits\n","\n","# 設定輸入和輸出大小\n","input_size = 20000  # Adjust based on your vocabulary size\n","output_size = 5\n","\n","# 初始化模型\n","bert_model = MyBertModel(input_size, output_size)\n","\n","# 初始化tokenizer\n","total_songs = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2', 'I2', 'J2', 'K2', 'L2', 'M2', 'N2', 'O2', 'P2', 'Q2', 'R2', 'S2', 'T2','U2','V2','W2','X2','Y2']\n","# Convert song names to indices\n","def song_to_index(song_names):\n","    string = ''\n","    for song in song_names:\n","      string += total_songs.index(song)\n","    return [total_songs.index(song) for song in song_names]\n","\n","# 定義輸入\n","input_text = ['A B C D E F G H I J K L M N O P Q R S T', 'A2 B2 C2 D2 E2 F2 G2 H2 I2 J2 K2 L2 M2 N2 O2 P2 Q2 R2 S2 T2']\n","input_ids_list = [song_to_index for text in input_text]\n","\n","# 定義標籤\n","label_text = ['U V W X Y', 'U2 V2 W2 X2 Y2']\n","label_ids_list = [tokenizer.encode(label_text, return_tensors='pt', padding=False, truncation=True, max_length=10) for text in label_text]\n","\n","# 訓練模型\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(bert_model.parameters(), lr=0.001)\n","\n","# 訓練迴圈\n","epochs = 3\n","for epoch in range(epochs):\n","    for input_ids, label_ids in zip(input_ids_list, label_ids_list):\n","        optimizer.zero_grad()\n","        outputs = bert_model(input_ids, attention_mask=(input_ids != 0))\n","        loss = criterion(outputs, label_ids.squeeze())\n","        loss.backward()\n","        optimizer.step()\n","\n","# 測試模型\n","with torch.no_grad():\n","    for input_ids in input_ids_list:\n","        output_ids = bert_model(input_ids, attention_mask=(input_ids != 0)).topk(output_size).indices[0].tolist()\n","        output_songs = [total_song[i] for i in output_ids]\n","\n","        # 打印結果\n","        print(\"Input Songs:\", tokenizer.decode(input_ids[0], skip_special_tokens=True).split())\n","        print(\"Generated Songs:\", output_songs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"l-cg7A8SIIJx","executionInfo":{"status":"error","timestamp":1703145792606,"user_tz":-480,"elapsed":2504,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"0899eba4-fc2f-4f55-80c0-dd80d266ff11"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-2230571c8477>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-2230571c8477>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'size'"]}]},{"cell_type":"code","source":["import torch\n","from transformers import BertModel, BertTokenizer\n","\n","# 使用BERT模型和标记器\n","model = BertModel.from_pretrained('bert-base-uncased')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# 定义新的输入形状\n","max_seq_len = 128\n","input_ids = torch.randint(0, 1000, (1, max_seq_len))\n","attention_mask = torch.ones((1, max_seq_len))\n","\n","# 用新的输入调用model\n","output = model(input_ids, attention_mask)\n","\n","# 将模型的输出堆叠成固定的形状\n","output_shape = (5, 768)\n","fixed_output = torch.zeros(output_shape)\n","fixed_output[:, :] = output[0][:, 0, :]  # 将输出的第一个位置的 [CLS] token 的隐藏状态复制到 fixed_output\n","\n","# 显示 fixed_output 的形状\n","print(fixed_output.shape)  # 输出：torch.Size([1, 768])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wGeNh3AWsF1K","executionInfo":{"status":"ok","timestamp":1703201084265,"user_tz":-480,"elapsed":1987,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"40e72dec-f8e1-4231-ac24-7dd628f37dbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 768])\n"]}]},{"cell_type":"code","source":["from datetime import datetime, timedelta\n","import torch\n","from transformers import BertModel, BertTokenizer\n","\n","# 使用BERT模型和标记器\n","model = BertModel.from_pretrained('bert-base-uncased')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# 假设 song_ids 是包含20首歌曲id的列表\n","song_ids = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n","\n","# 将歌曲id转换为字符串，并使用空格连接\n","song_ids_str = ' '.join(map(str, song_ids))\n","\n","# 定义新的输入形状\n","max_seq_len = 128  # 可根据需要调整\n","input_ids = tokenizer.encode(song_ids_str, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True, truncation=True)\n","attention_mask = torch.ones((1, max_seq_len))\n","\n","# 用新的输入调用model\n","output = model(torch.tensor([input_ids]), attention_mask)\n","\n","# 提取 [CLS] token 的隐藏状态\n","cls_embedding = output[0][:, 0, :]\n","\n","# 将隐藏状态转换为字符串\n","final_output_str = ' '.join(map(str, cls_embedding.tolist()))\n","\n","# 显示 final_output_str\n","print(final_output_str)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-Fc8NLHuSTs","executionInfo":{"status":"ok","timestamp":1703202399507,"user_tz":-480,"elapsed":3164,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"424d7d9c-7585-4de8-d4dc-05d1da680c08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.3195570111274719, 0.4280405044555664, 0.5585589408874512, 0.4973354935646057, -0.007525980938225985, -0.44585809111595154, 0.2989266812801361, -0.01971552148461342, 0.1744040697813034, -0.14784805476665497, -0.2903769612312317, -0.48642697930336, -0.07700340449810028, 0.4377892315387726, 0.4711739420890808, 1.070137619972229, -0.3097708523273468, 0.5950692296028137, -0.3302118480205536, 0.258063405752182, 0.5387468934059143, 0.3174436092376709, 0.782282829284668, 0.06433650851249695, -0.6479944586753845, 0.02694805897772312, 0.1207866370677948, -0.9755364656448364, -0.49601444602012634, 0.20584125816822052, -0.6337382197380066, 0.3621390759944916, 0.15745748579502106, -0.2028491199016571, 0.0149107426404953, -0.22828947007656097, -0.3661006689071655, -0.10994458943605423, 0.6241545677185059, 0.2743743360042572, 0.1105203926563263, -0.5393616557121277, 0.5848770141601562, -0.05721202492713928, 0.20648832619190216, -0.4382016956806183, -3.2039926052093506, 0.2949097156524658, -0.012106136418879032, -0.6081083416938782, -0.04775014519691467, -0.4201383590698242, 0.782874345779419, -0.04943273589015007, -0.012342976406216621, 0.4891592562198639, -0.0069558643735945225, -0.21852296590805054, 1.4402515888214111, 0.2137957066297531, -0.015687860548496246, 0.41316136717796326, -0.7495754361152649, 0.17372359335422516, -0.252930611371994, 0.6914251446723938, -0.34056687355041504, -0.010174045339226723, -0.49239280819892883, 0.20345589518547058, 0.19752921164035797, 0.374571293592453, 0.5499731302261353, 0.36970028281211853, -0.014636488631367683, -0.18037700653076172, -0.11346523463726044, 0.8579441905021667, -0.30275383591651917, -0.18629442155361176, 0.30382269620895386, -0.41606324911117554, 0.07241063565015793, -0.5732888579368591, 0.4712171256542206, 0.17291884124279022, 0.7558401226997375, -0.2260311245918274, -0.11081939935684204, 0.33555519580841064, 0.6725967526435852, 0.053112488240003586, 0.6951135993003845, -0.13264615833759308, 0.13890542089939117, -0.05652815103530884, 0.02347670868039131, 0.07066178321838379, -0.10904793441295624, -0.540886402130127, -0.298981249332428, 1.0097801685333252, 0.18892858922481537, -0.3164024353027344, 0.10405482351779938, 0.15712058544158936, -0.8787267208099365, 0.3246638774871826, -0.07925517112016678, -0.835063636302948, -0.17088061571121216, 0.5216318368911743, -0.3103179335594177, 0.03415417671203613, 0.4054001271724701, 0.11560928821563721, 0.6102434992790222, -0.2867513597011566, 0.7011585831642151, -0.2154659777879715, 0.10240025818347931, 0.34170281887054443, 0.21211907267570496, -0.342515230178833, 0.13019077479839325, 0.16276335716247559, -0.21370646357536316, -1.534258484840393, -0.025653647258877754, 0.8568975329399109, 0.05776233971118927, -0.2061542272567749, -0.3157922327518463, 0.44551923871040344, -0.4217756986618042, -0.5128164291381836, -0.2683009207248688, 0.4162975549697876, -0.2083476334810257, -0.10455921292304993, -1.0318000316619873, -0.14813414216041565, -1.2138241529464722, -0.30983129143714905, -0.19424940645694733, -0.1895919293165207, 0.39794400334358215, 0.46357443928718567, -0.7851206064224243, -0.361044704914093, 0.019646206870675087, -0.16469164192676544, -0.6530018448829651, -0.4913640320301056, -0.28416094183921814, -0.36918601393699646, 0.7814995050430298, -0.21031038463115692, -0.2013661116361618, 0.6525112986564636, -0.018284324556589127, 0.4026874303817749, -0.09095501154661179, 0.2694037854671478, 0.36018046736717224, -0.016984377056360245, 0.2342630922794342, 0.2862549126148224, 0.20662589371204376, -0.07405269145965576, 0.11992819607257843, -0.33182013034820557, 0.45517247915267944, -0.6866983771324158, -0.006204349920153618, 0.09952598810195923, 0.05576089024543762, 0.5330755114555359, 0.6917349696159363, 0.13120132684707642, -0.38860514760017395, -0.13084053993225098, -0.6684058904647827, 0.10656696557998657, -0.2830704152584076, 0.5943576097488403, -0.1041332483291626, 1.0353564023971558, 0.36867520213127136, 0.3562759757041931, -1.3468471765518188, 0.03761940822005272, 0.2465723156929016, 0.5729345083236694, 0.4233746826648712, 0.3429318070411682, -0.6282832026481628, 0.3694871962070465, -0.06500135362148285, -0.3355593681335449, -0.21133342385292053, 0.7484645843505859, -0.20013578236103058, 0.5674680471420288, 0.04408321902155876, 2.693310260772705, -0.028887426480650902, 0.14756591618061066, -0.2679036557674408, -0.40799593925476074, -0.6393527984619141, -0.6856740713119507, -0.4977482855319977, 0.12599655985832214, -0.2689087986946106, -0.7702171802520752, -0.551124632358551, -0.26419389247894287, 0.2565145492553711, 0.5015940070152283, -0.6171836256980896, -0.4410204589366913, -0.01140478253364563, 0.5807019472122192, -0.016887707635760307, -0.31678053736686707, -0.4446623921394348, -0.1686769425868988, 0.13933102786540985, -1.5049996376037598, -0.023891856893897057, -1.0115567445755005, -0.5007197856903076, -0.4105345606803894, -0.0529303178191185, -0.020606618374586105, 0.05589907988905907, -0.3296438753604889, 0.1797758787870407, 0.5006734728813171, -0.17317593097686768, 0.5746850371360779, 0.12444107979536057, -0.27464720606803894, -0.33064454793930054, -0.272223562002182, -0.24566388130187988, -0.4282764792442322, 0.046189457178115845, 0.07070757448673248, -0.10314355045557022, 0.1465473771095276, -0.16425204277038574, 0.36095109581947327, 0.373274028301239, 0.26810115575790405, 0.0031058804597705603, -0.015567874535918236, -0.3498499095439911, -0.7169163823127747, -0.3645131289958954, 0.3299185335636139, -0.37532249093055725, 0.2646522521972656, -0.1443798542022705, 0.04249204322695732, 0.1628401279449463, -0.15155893564224243, -0.38787841796875, 0.012857240624725819, 0.2599470913410187, -0.337604820728302, -0.5591962933540344, -0.6678574085235596, 0.06049283221364021, -0.5268275141716003, 1.1010948419570923, 0.02600572630763054, -0.06281658262014389, 0.05179082229733467, -0.024233372882008553, -0.3018556833267212, -0.5986376404762268, 0.04864129796624184, -0.31675592064857483, -0.5685559511184692, 0.516623318195343, -0.31931352615356445, 0.7402277588844299, 0.506132960319519, -0.3824009597301483, 0.5107983350753784, 0.1542465090751648, 0.3019815683364868, 0.005196839105337858, -0.8946003913879395, -0.10348911583423615, -0.33365732431411743, 0.45850640535354614, 0.31509819626808167, -0.8344978094100952, 0.826634407043457, -0.6621308922767639, 0.7850170135498047, -0.16392791271209717, 0.014362438581883907, -0.32596513628959656, 0.3319653570652008, -4.900623798370361, 0.34864962100982666, -0.4058701992034912, 0.05220656096935272, 0.03995104134082794, 0.5093139410018921, 0.9943867921829224, 0.5154032111167908, -0.4071061909198761, 0.316165566444397, 0.2961185872554779, 0.7493669986724854, -0.27213212847709656, -0.113730289041996, -0.3706243634223938, -0.42675378918647766, 0.9009918570518494, 0.19093595445156097, -0.01549159362912178, 0.1625191867351532, -0.5164899230003357, 0.1410411149263382, 0.5391037464141846, -0.5758002996444702, 0.6252344250679016, 0.3136422634124756, 0.10473291575908661, -0.2621396481990814, -0.01620430126786232, 0.28733405470848083, -0.12178029865026474, -0.5810078382492065, -0.05155632272362709, -0.04054148495197296, 0.01538859959691763, -0.3975040018558502, -0.2369769662618637, -0.5406811833381653, 0.3172910809516907, -0.40256643295288086, 0.4777803421020508, -0.6726146936416626, 0.08733160048723221, -0.26096484065055847, 0.31845220923423767, -0.3545025587081909, -0.11741098016500473, 1.300484299659729, 0.2097880095243454, 0.5847064852714539, -0.07955632358789444, 0.34539318084716797, 0.18253399431705475, -0.3479922115802765, -0.2813653349876404, -0.29402077198028564, 0.21116402745246887, -0.15485115349292755, -0.5312539935112, 0.32510602474212646, 0.7413862943649292, 0.38761958479881287, -0.6794891357421875, 0.35606110095977783, 0.056930750608444214, -0.4260358512401581, -0.23002231121063232, -0.08599260449409485, -0.9535389542579651, 0.3933853209018707, -1.0547511577606201, -0.4639036953449249, 0.0032986982259899378, -0.9431139826774597, 0.3371031880378723, -0.4456736445426941, -0.11154807358980179, 0.1311776340007782, 0.15960730612277985, 0.2787151336669922, -0.7053199410438538, 0.11089743673801422, 0.3464182913303375, 0.7197893261909485, -0.41007471084594727, 0.8660436868667603, -0.5865882635116577, 0.6653161644935608, 0.14980706572532654, 0.6335967779159546, -0.44126275181770325, -0.13799865543842316, 0.42417633533477783, -0.03574663773179054, -0.10346765071153641, 0.9659428000450134, 0.266335129737854, -0.07575502246618271, 0.6898940205574036, 0.2027733474969864, 0.7793086171150208, -0.013297384604811668, -0.2985225319862366, 0.24296125769615173, -0.2477920949459076, -0.0964212715625763, -0.3578989803791046, -0.1609981656074524, 0.56932133436203, -0.0718739777803421, 0.03164913132786751, 0.5001932382583618, -0.2964249551296234, -0.11885428428649902, 0.3089101314544678, -0.4067873954772949, -0.10459502786397934, 0.4426654279232025, 0.27221402525901794, -0.2247784286737442, -0.08452945202589035, -0.38995975255966187, -0.5771616697311401, -0.30231520533561707, -0.785215437412262, 0.364141583442688, 0.0022781493607908487, 0.4785427153110504, 0.0685487911105156, 0.06388311833143234, -0.2773534655570984, -0.3147425651550293, -0.8598389625549316, -0.30394917726516724, 0.20069386065006256, 0.4281204640865326, 0.42174816131591797, -0.5924504399299622, 0.4253671169281006, -0.02288195490837097, 0.5676527619361877, 0.06974665820598602, -0.1298215091228485, 0.14983518421649933, -0.2218216061592102, -0.1370699256658554, 0.5912222266197205, -0.2522990107536316, 0.11382906138896942, 0.3908093273639679, -0.07464610040187836, 0.21629171073436737, 0.18365344405174255, -0.4096689820289612, 0.4608836770057678, 0.35716840624809265, -0.12080651521682739, -0.6008462905883789, -0.4335906505584717, -0.402521014213562, 0.6105607748031616, -0.03570199012756348, -1.5185821056365967, -0.26081204414367676, 0.5480100512504578, 0.30591854453086853, 0.7179402112960815, -0.276994526386261, 0.16629824042320251, 0.1478482186794281, -0.38631197810173035, 0.26474690437316895, -0.21885226666927338, 0.24950872361660004, -0.1338089406490326, 0.12739384174346924, 0.10782915353775024, -0.034486111253499985, 0.31199243664741516, 0.22421549260616302, -0.12585902214050293, -0.03177960589528084, -0.04629819840192795, 0.2723146677017212, -0.0696617066860199, 0.32930508255958557, -0.2745373547077179, -0.10628635436296463, -0.29294553399086, 0.5928512215614319, -0.07472415268421173, -0.10792188346385956, 0.10786519199609756, -0.7365555167198181, -0.0449584499001503, -0.22343730926513672, 0.29261693358421326, 1.0067206621170044, 0.13041353225708008, 0.39613497257232666, -0.5645806789398193, 0.23583006858825684, -0.150431290268898, 0.13706421852111816, 0.49768829345703125, 0.2814546525478363, -0.40423399209976196, -0.0038347819354385138, 0.18802869319915771, 0.03991514816880226, 0.15947279334068298, 0.03783409297466278, 0.06239648163318634, 0.16527169942855835, 0.12861722707748413, 0.13794715702533722, -0.46881699562072754, -0.31135156750679016, -0.24329081177711487, 0.037958718836307526, -0.08812353014945984, 0.3438511788845062, 0.8987740874290466, -0.33690282702445984, 0.23456400632858276, -0.42670390009880066, -0.2561909854412079, -0.30886316299438477, 0.7069732546806335, -0.11109303683042526, -0.5499353408813477, 0.22207318246364594, -0.11777826398611069, 0.07276803255081177, -0.7891953587532043, 0.05910025164484978, -0.22504691779613495, -0.4108116924762726, 0.06287094950675964, 1.080449104309082, -0.20869050920009613, -0.23780658841133118, 0.9315410256385803, -0.9963518977165222, 0.504587709903717, 0.5059094429016113, 0.09625474363565445, 0.07177058607339859, -0.027916831895709038, 0.12976180016994476, 0.39085158705711365, 0.07016923278570175, 0.012031636200845242, -0.5560808181762695, 0.6551098823547363, -0.10363832116127014, -0.1213972270488739, -0.4528074860572815, -0.3876732885837555, -0.37733224034309387, -0.33865123987197876, 0.5711870789527893, -0.18794649839401245, 0.14004170894622803, 0.13386361300945282, -0.059508319944143295, 0.02394784428179264, 1.1538029909133911, 0.12122535705566406, -0.1451462060213089, -0.5953800678253174, 0.526397705078125, -0.13801822066307068, 0.27969422936439514, -0.1224093958735466, 0.18212890625, 0.5176151394844055, 0.250701904296875, 0.5578276515007019, -0.6345296502113342, 0.3304840326309204, 0.15293385088443756, -0.08961273729801178, 0.08684138208627701, 0.060573726892471313, -0.024058282375335693, -0.00035576833761297166, -0.7078500390052795, 0.18970178067684174, 0.17102129757404327, -0.6375529170036316, 0.24086035788059235, -0.6111445426940918, -0.5672304630279541, 0.00446187611669302, 0.7233545184135437, 0.3647614121437073, -0.2525987923145294, -0.23783612251281738, -0.1779182255268097, -0.2877849340438843, 0.40006738901138306, 0.8563273549079895, -0.7341734766960144, -0.44398537278175354, 0.1339835822582245, -0.15139447152614594, -0.05738401785492897, -0.4213936924934387, -0.33579355478286743, 0.24498996138572693, 0.033092088997364044, 0.25526654720306396, 0.31960171461105347, -0.06536081433296204, -0.2763015031814575, -0.40461814403533936, -0.2200293391942978, -0.0887603834271431, 0.6775170564651489, 0.06700321286916733, 0.5116684436798096, 0.5694754123687744, -0.6280546188354492, -0.11002514511346817, 0.41934269666671753, 0.4771057069301605, -0.25551679730415344, -0.25384798645973206, 0.8110217452049255, -0.31665661931037903, -0.9323541522026062, -0.11111187189817429, -0.01063504908233881, -0.30274224281311035, 0.2902703583240509, -0.5345970392227173, -1.112732172012329, -0.4085535705089569, 0.2224237024784088, -0.2616024315357208, 0.14076144993305206, 0.7420111894607544, -0.49898993968963623, -0.5763368010520935, -0.13940323889255524, 0.3360040485858917, -0.3449520170688629, -0.04758968949317932, -0.29788297414779663, -0.05006267502903938, 0.13268505036830902, 0.5598915219306946, 0.547231137752533, -0.02563079260289669, 0.2548919916152954, 0.35165199637413025, -0.9960336089134216, -0.5373184084892273, -0.9547739624977112, -0.008191072382032871, 0.09687548875808716, -0.022920742630958557, 0.13939642906188965, -0.07217580080032349, -0.177622988820076, 0.5201795101165771, 0.5978603959083557, 0.3695331811904907, -0.4111984670162201, 0.6186800003051758, 0.07735642790794373, 0.08454816788434982, -0.0967051088809967, 0.24010440707206726, 0.47139281034469604, 0.05140495300292969, -0.3303583860397339, 0.014509493485093117, 0.030102591961622238, -0.07586675882339478, -0.595535933971405, 0.058184120804071426, -0.5178892612457275, 0.20581047236919403, 1.2598845958709717, -0.406094491481781, 0.12484212219715118, 0.1697024703025818, -0.05607442185282707, 0.5603166818618774, -0.034140173345804214, 0.05569279193878174, 0.11637135595083237, -0.06361767649650574, 0.6412982940673828, -0.13880664110183716, -0.14724735915660858, 0.06034081056714058, -0.21812517940998077, 0.6728407740592957, 0.09833288937807083, 0.45825907588005066, 0.26309263706207275, -0.19273044168949127, 0.2019660323858261, 0.008142972365021706, 0.9227505326271057, -0.30334916710853577, -0.3988759517669678, -0.026247549802064896, -0.31228217482566833, 0.8329416513442993, 0.1288508176803589, -0.4366298019886017, -0.6813317537307739, 0.0034859220031648874, -0.1018049418926239, 0.020153794437646866, -0.8114169836044312, -0.6995741128921509, -0.3554946184158325, 0.2586599290370941, 0.36171144247055054, 0.2159295380115509, -0.14061106741428375, 0.4233781099319458, -0.003432005178183317, -0.6183761358261108, 0.3547356426715851, -0.2723262310028076, -0.03178185969591141, -0.26377731561660767, 0.257284551858902, -0.15290410816669464, -0.45256462693214417, 0.8434155583381653, 0.41697487235069275, 0.5236203670501709, -0.07131040096282959, 0.5553239583969116, 0.6602185964584351, 0.6214475631713867, 0.00014277754235081375, -2.051440715789795, -0.4602142870426178, -0.0829303041100502, -0.19912341237068176, -0.1752305030822754, 0.013239284977316856, -0.460753470659256, -0.10896705090999603, -0.18508170545101166, -0.276264488697052, 0.36898064613342285, -0.5990530848503113, -0.12111280113458633, -0.4173470735549927, 0.4686795473098755, -0.3655149042606354]\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel, BertTokenizer, BertConfig\n","\n","# 定義BERT模型\n","class MyBertModel(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(MyBertModel, self).__init__()\n","        self.bert = BertModel(\n","            BertConfig(\n","                vocab_size=input_size,\n","                hidden_size=768,  # You can adjust the hidden size as needed\n","                num_hidden_layers=12,  # You can adjust the number of layers as needed\n","                num_attention_heads=12,  # You can adjust the number of attention heads as needed\n","                intermediate_size=3072,  # You can adjust the intermediate size as needed\n","            )\n","        )\n","        self.fc = nn.Linear(768, output_size)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        logits = self.fc(outputs.pooler_output)\n","        return logits\n","# 初始化tokenizer\n","total_songs = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2', 'I2', 'J2', 'K2', 'L2', 'M2', 'N2', 'O2', 'P2', 'Q2', 'R2', 'S2', 'T2','U2','V2','W2','X2','Y2']\n","# Convert song names to indices\n","def song_to_index(song_names):\n","    string = ''\n","    for song in song_names:\n","      string += total_songs.index(song)\n","    return [total_songs.index(song) for song in song_names]\n","# 設定輸入和輸出大小\n","input_size = 20000  # Adjust based on your vocabulary size\n","output_size = 5\n","\n","# 初始化模型\n","bert_model = MyBertModel(input_size, output_size)\n","\n","# 初始化tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# 定義輸入\n","input_text = 'A B C D E F G H I J K L M N O P Q R S T'\n","input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","\n","# 生成輸出\n","attention_mask = torch.ones_like(input_ids)  # 簡單使用全1的attention mask\n","with torch.no_grad():\n","    output_ids = bert_model(input_ids, attention_mask=attention_mask).topk(output_size).indices[0].tolist()\n","\n","# 將輸出轉換為歌曲名稱\n","output_songs = [total_songs[i] for i in output_ids]\n","\n","# 打印結果\n","print(\"Input Songs:\", input_text.split())\n","print(\"Generated Songs:\", output_songs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3J6i0RPH_Ouj","executionInfo":{"status":"ok","timestamp":1703147328845,"user_tz":-480,"elapsed":4,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"063e84aa-949e-44b0-a04e-406382140d9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Songs: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T']\n","Generated Songs: ['B', 'D', 'E', 'C', 'A']\n"]}]},{"cell_type":"code","source":["# 导入必要的库\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.nn.functional import softmax\n","\n","# 加载预训练的BERT模型和分词器\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n","\n","# 设置设备\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# 定义输入和输出的歌曲数量\n","num_input_songs = 20\n","num_output_songs = 5\n","\n","# 定义输入歌曲id和输出歌曲id的字符串\n","input_song = 'id_of_song_1 id_of_song_2 id_of_song_3 id_of_song_4 id_of_song_5 id_of_song_6 id_of_song_7 id_of_song_8 id_of_song_9 id_of_song_10 id_of_song_11 id_of_song_12 id_of_song_13 id_of_song_14 id_of_song_15 id_of_song_16 id_of_song_17 id_of_song_18 id_of_song_19 id_of_song_20'\n","\n","# 将输入歌曲id分词并转换为模型输入\n","input_tokens = tokenizer.encode_plus(input_song, add_special_tokens=True, return_tensors='pt')\n","input_tokens = input_tokens.to(device)\n","\n","# 使用BERT模型进行推断\n","with torch.no_grad():\n","    logits = model(**input_tokens).logits\n","\n","# 对模型输出进行softmax，得到每首歌的概率分布\n","probs = softmax(logits, dim=1)[0]\n","\n","# 获取概率最高的5首歌的索引\n","top5_song_indices = torch.topk(probs, num_output_songs).indices\n","\n","# 打印输出歌曲id\n","output_song = ' '.join([f'id_of_song_{i+1}' for i in top5_song_indices])\n","print(\"Output Song IDs:\", output_song)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441,"referenced_widgets":["65bb190eef8c45f1a8616ca053b8a6b1","7cdd7112ae62435092bb00ea69e275a8","11b1337301344ceda02b06a491c7dbee","c58a4089d7c448e2bcfa085be9530f2c","f7f44bd24bca48138c75052786035b99","a211cae2f6764b86a3cd0ff369a2fcdd","e3b67790a8af48a6b57266615f272aa1","095c35a72724417f8bbe51b909cf598c","b3232ba7bd4f4a2ab14143b35e27e280","e3338779dc42425980aba5a730b21f34","42045bf3f1164473b5d40f7648bc1a48","0ed5ebef5958463a8c9a185f8f08319c","b40b67901d7247fab713b8dd9fc46cca","f3d224d57e7744e19fa9c69eaad8af85","872cb0d6493149828bdf38f2f3b856a0","c155a461a9f94f33b3d215fc8232ea1f","b04098468dad44f29c4682c948d513a5","abc2099ec84444f080319218711f8bd1","6bc1c4f272834b4695962473fbb08bba","4ac6d9a9bd9b4b308d6a555e3be0b735","64af82e5cbf6429184abc7d7ef231b6c","4d19392065484111a860db23d1dbedbc","bd272e92df07457c992822957f7988ea","52f42d3a1802457c8ff8a4feb1242c60","2e3d3364124944a6bf0c8e25a5db72bc","37a411708b634dbe8f13368acbfed45d","3e96c3390849475cbf35c5fa1c5d1adc","5d5503abdc684678bb4f96059753db32","c84d2f054b0147e39ecdaa6cc4cfe1c7","daa54d651f04424ebfdff8e552cb7c5a","a3d4df9d67c54b02a409a533454800e2","bfebc1b57c3c4084945d28003003b4ef","2ae1ed7d68064851902a423e9a0b9311","1a110a472f2b43ea8d63911c812060d0","9c60935cc7a2497abaee1023161b921b","4d7080df9fc84255bbcd419532751e23","0b86f4217b7a4b99b6946706f0f9b48c","d536c83edc5248968b1d823f3df67cc1","76a19ab2fa474f0db51315c9a2e98a69","fe95e0f1d8244a5dab3cf375a6bd455b","d9c8ddcd7783443ab757e1f44d249e30","cab5a67a9b214ec49c8bc77f7d0a6e24","806b9b532d2f4423b3ae20c4b7135165","9af89377141f4dbbb61d176b4fb13bc1","5bdcd4f1179e4daa90163a62c9e070ff","ac56e201e95c450ea6ec777122c7e1bc","a9e83dec58004f92b0c19dde50dfb47d","d9b2f2356f9d462fb818ebfadd8d25e7","43abfa238d54420b8ff717e5b82157e3","b2eb21d4147c4503ae79276dcb8b335e","1a13b6917a5e401e8515c40c8cef9c77","ca9f90ea67c84a1d9144f5107d121680","0d33f6e09a5e4f55bd7d1d133609269b","4286ce0463194c82bdd75d477db6bd65","b9359cb5cee3480a9b5e7b8cc9859946"]},"id":"sRvsofVC1Cs6","executionInfo":{"status":"error","timestamp":1703222919505,"user_tz":-480,"elapsed":21724,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"493d7b1f-25e1-4e0c-fafb-04e34d8c8342"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65bb190eef8c45f1a8616ca053b8a6b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed5ebef5958463a8c9a185f8f08319c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd272e92df07457c992822957f7988ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a110a472f2b43ea8d63911c812060d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bdcd4f1179e4daa90163a62c9e070ff"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-5aec3ca8707a>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# 获取概率最高的5首歌的索引\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtop5_song_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_output_songs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# 打印输出歌曲id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"]}]},{"cell_type":"code","source":["input_song = 'id_of_song_1 id_of_song_2 id_of_song_3 id_of_song_4 id_of_song_5 id_of_song_6 id_of_song_7 id_of_song_8 id_of_song_9 id_of_song_10 id_of_song_11 id_of_song_12 id_of_song_13 id_of_song_14 id_of_song_15 id_of_song_16 id_of_song_17 id_of_song_18 id_of_song_19 id_of_song_20'\n","output_song = 'id_of_song_2 id_of_song_5 id_of_song_20 id_of_song_11 id_of_song_17'"],"metadata":{"id":"GU242CHS15Pn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","input = []\n","for j in range(2):\n","  text = ''\n","  for i in range(5):\n","    text += \"song_id_\"+str(random.randint(1,20))+\" \"\n","  input.append(text[:-1])"],"metadata":{"id":"muUMdAdYZ9zr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUX4LUuna0Ra","executionInfo":{"status":"ok","timestamp":1703237678002,"user_tz":-480,"elapsed":3,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"cfa90a11-c1a1-44e2-b453-5f27a3b7e86f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['song_id_7 song_id_12 song_id_18 song_id_5 song_id_18', 'song_id_6 song_id_19 song_id_8 song_id_15 song_id_14']\n"]}]},{"cell_type":"code","source":["total_songs = []\n","for word in input_song.split(\" \"):\n","  total_songs.append(word)\n","print(total_songs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JhSDfWBFRPMt","executionInfo":{"status":"ok","timestamp":1703227535340,"user_tz":-480,"elapsed":11,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"34edb7a3-2f9e-4fe8-e564-d6c8cf9be9e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['id_of_song_1', 'id_of_song_2', 'id_of_song_3', 'id_of_song_4', 'id_of_song_5', 'id_of_song_6', 'id_of_song_7', 'id_of_song_8', 'id_of_song_9', 'id_of_song_10', 'id_of_song_11', 'id_of_song_12', 'id_of_song_13', 'id_of_song_14', 'id_of_song_15', 'id_of_song_16', 'id_of_song_17', 'id_of_song_18', 'id_of_song_19', 'id_of_song_20']\n"]}]},{"cell_type":"code","source":["# 生成輸出\n","with torch.no_grad():\n","    logits = bert_model(input_ids, attention_mask=attention_mask)\n","    output_ids = logits.argmax(dim=-1)[0].tolist()\n","\n","# 將輸出轉換為歌曲名稱，保證包含所有歌曲\n","output_songs = [total_songs[i] for i in output_ids]\n","\n","# 打印結果\n","print(\"Input Songs:\", input_text.split())\n","print(\"Generated Songs:\", output_songs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"id":"KT0DGlK7eQIq","executionInfo":{"status":"error","timestamp":1703147507272,"user_tz":-480,"elapsed":945,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"5be0608c-65d7-47df-b99b-20d2a4a72096"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-2c5c49801186>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 將輸出轉換為歌曲名稱，保證包含所有歌曲\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutput_songs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtotal_songs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 打印結果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"]}]},{"cell_type":"code","source":["logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l38-7B7ESPUi","executionInfo":{"status":"ok","timestamp":1703147541515,"user_tz":-480,"elapsed":7,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"af2e40b3-d821-44a9-a3e7-0ac14ea92e87"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0020,  0.3746, -0.0292,  0.1410,  0.1362]])"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SWWN22IvWw19","executionInfo":{"status":"ok","timestamp":1703146935704,"user_tz":-480,"elapsed":318,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"24230516-c2c8-4335-9d4a-5b1ac0b594dc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1373,  0.0085, -0.1494, -0.0316,  0.0720]],\n","       grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer\n","\n","# 定義自定義的數據集\n","class MyDataset(Dataset):\n","    def __init__(self, input_text, label_text, tokenizer, max_length=20):\n","        self.input_text = input_text\n","        self.label_text = label_text\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.input_text)\n","\n","    def __getitem__(self, idx):\n","        input_ids = self.tokenizer.encode(self.input_text[idx], return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length)\n","        label_ids = self.tokenizer.encode(self.label_text[idx], return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length)\n","        return {'input_ids': input_ids, 'label_ids': label_ids}\n","# 初始化tokenizer\n","total_songs = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2', 'I2', 'J2', 'K2', 'L2', 'M2', 'N2', 'O2', 'P2', 'Q2', 'R2', 'S2', 'T2','U2','V2','W2','X2','Y2']\n","# Convert song names to indices\n","def song_to_index(song_names):\n","    return [total_songs.index(song) for song in song_names]\n","\n","# 設定輸入和輸出大小\n","input_size = 20000  # Adjust based on your vocabulary size\n","output_size = 5\n","\n","# 初始化模型\n","bert_model = MyBertModel(input_size, output_size)\n","\n","# 初始化tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# 定義輸入\n","input_texts = ['A B C D E F G H I J K L M N O P Q R S T ', 'A2 B2 C2 D2 E2 F2 G2 H2 I2 J2 K2 L2 M2 N2 O2 P2 Q2 R2 S2 T2 ']\n","label_texts = ['U V W X Y ', 'U2 V2 W2 X2 Y2 ']\n","\n","# 創建數據集和數據載入器\n","dataset = MyDataset(input_text, label_text, tokenizer)\n","dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n","\n","# 訓練模型\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(bert_model.parameters(), lr=0.001)\n","\n","# 訓練迴圈\n","epochs = 3\n","for epoch in range(epochs):\n","    for input_text, label_text in zip(input_texts, label_texts):\n","        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","        label_ids = tokenizer.encode(label_text, return_tensors='pt')\n","\n","        optimizer.zero_grad()\n","        outputs = bert_model(input_ids, attention_mask=(input_ids != 0))\n","\n","        # Assuming label_ids is your modified tensor\n","        loss = criterion(outputs, label_ids)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","# 測試模型\n","with torch.no_grad():\n","    for batch in dataloader:\n","        input_ids = batch['input_ids']\n","        output_ids = bert_model(input_ids, attention_mask=(input_ids != 0)).topk(output_size).indices[0].tolist()\n","        output_songs = [total_song[i] for i in output_ids]\n","\n","        # 打印結果\n","        print(\"Input Songs:\", tokenizer.decode(input_ids[0][0], skip_special_tokens=True).split())\n","        print(\"Generated Songs:\", output_songs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"t7ijbjjqExe4","executionInfo":{"status":"error","timestamp":1703147073423,"user_tz":-480,"elapsed":3529,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"c4d0c8d3-213b-41a9-dbc4-14ab7e00054a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-c7f9199886e8>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Assuming label_ids is your modified tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (0)."]}]},{"cell_type":"code","source":["loss = criterion(outputs, label_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-A7YIk6cOM8","executionInfo":{"status":"ok","timestamp":1703147076520,"user_tz":-480,"elapsed":4,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"10a11038-bad3-49de-835a-a88527a76e2d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0331, 0.4820, 0.1957, 0.4740, 0.3058]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWrapu16cQci","executionInfo":{"status":"ok","timestamp":1703147144381,"user_tz":-480,"elapsed":8,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"c68a3371-5795-499c-87fd-b349db4bcc29"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0331, 0.4820, 0.1957, 0.4740, 0.3058]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["label_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jq6xBkIqewex","executionInfo":{"status":"ok","timestamp":1703147150224,"user_tz":-480,"elapsed":393,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"9f1e9dfa-873f-44e0-fea3-a315ffd627dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 101, 1057, 1058, 1059, 1060, 1061,  102]])"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# 模型的输出\n","outputs = torch.tensor([[0.0331, 0.4820, 0.1957, 0.4740, 0.3058]], requires_grad=True)\n","\n","# 目标标签的类别索引\n","label_ids = torch.tensor([[101, 1057, 1058, 1059, 1060, 1061, 102]])\n","\n","# 将模型输出转换为类别索引\n","_, predicted_labels = outputs.max(dim=1)\n","\n","# 使用交叉熵损失函数\n","criterion = nn.CrossEntropyLoss()\n","loss = criterion(outputs, predicted_labels)\n","\n","# 打印损失\n","print(loss.item())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75DnX-lxfD0l","executionInfo":{"status":"ok","timestamp":1703147225896,"user_tz":-480,"elapsed":472,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"99fca003-2f8c-4445-a267-63aa882e1ef0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.439799427986145\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel, BertTokenizer, BertConfig\n","\n","# 定義BERT模型\n","class MyBertModel(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(MyBertModel, self).__init__()\n","        self.bert = BertModel(\n","            BertConfig(\n","                vocab_size=input_size,\n","                hidden_size=768,  # You can adjust the hidden size as needed\n","                num_hidden_layers=12,  # You can adjust the number of layers as needed\n","                num_attention_heads=12,  # You can adjust the number of attention heads as needed\n","                intermediate_size=3072,  # You can adjust the intermediate size as needed\n","            )\n","        )\n","        self.fc = nn.Linear(768, output_size)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        logits = self.fc(outputs.pooler_output)\n","        return logits\n","\n","# 初始化tokenizer\n","total_songs = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'H2', 'I2', 'J2', 'K2', 'L2', 'M2', 'N2', 'O2', 'P2', 'Q2', 'R2', 'S2', 'T2','U2','V2','W2','X2','Y2']\n","# Convert song names to indices\n","def song_to_index(song_names):\n","    return [total_songs.index(song) for song in song_names]\n","\n","# 設定輸入和輸出大小\n","input_size = 20000  # Adjust based on your vocabulary size\n","output_size = 5\n","\n","# 初始化模型\n","bert_model = MyBertModel(input_size, output_size)\n","\n","# 初始化tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# 定義輸入\n","input_texts = ['A B C D E F G H I J K L M N O P Q R S T ', 'A2 B2 C2 D2 E2 F2 G2 H2 I2 J2 K2 L2 M2 N2 O2 P2 Q2 R2 S2 T2 ']\n","label_texts = ['U V W X Y ', 'U2 V2 W2 X2 Y2 ']\n","\n","# 處理成模型可接受的格式\n","input_ids_list = [tokenizer.encode(text, return_tensors='pt', padding='max_length', truncation=True, max_length=20) for text in input_texts]\n","label_ids_list = [tokenizer.encode(text, return_tensors='pt', padding='max_length', truncation=True, max_length=20) for text in label_texts]\n","\n","# 生成輸出\n","with torch.no_grad():\n","    output_ids_list = [bert_model(input_ids, attention_mask=(input_ids != 0)).topk(output_size).indices[0].tolist() for input_ids in input_ids_list]\n","\n","# 將輸出轉換為歌曲名稱\n","output_songs_list = [[total_songs[i] for i in output_ids] for output_ids in output_ids_list]\n","\n","# 打印結果\n","for input_text, output_songs in zip(input_texts, output_songs_list):\n","    print(\"Input Songs:\", input_text.split())\n","    print(\"Generated Songs:\", output_songs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"fouFrd80RPts","executionInfo":{"status":"error","timestamp":1703145018054,"user_tz":-480,"elapsed":3620,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"ccfbbabe-3d1b-4d60-f89f-c3c7614e6398"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-a79e3f0905a6>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# 生成輸出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0moutput_ids_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# 將輸出轉換為歌曲名稱\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-a79e3f0905a6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# 生成輸出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0moutput_ids_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# 將輸出轉換為歌曲名稱\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-a79e3f0905a6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index out of range in self"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel, BertConfig\n","import torch.optim as optim\n","\n","class SongRecommendationModel(nn.Module):\n","    def __init__(self, input_size, output_size, hidden_size):\n","        super(SongRecommendationModel, self).__init__()\n","\n","        # 使用BertModel作為基礎模型\n","        self.bert = BertModel(BertConfig(hidden_size=hidden_size))\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input_ids):\n","        # 使用BertModel獲取輸入序列的表示\n","        outputs = self.bert(input_ids)\n","        pooled_output = outputs.pooler_output\n","\n","        # 使用全連接層進行預測\n","        output = self.fc(pooled_output)\n","        return output.view(-1, output_size)\n","\n","# 設置模型參數\n","input_size = 20  # 輸入序列的長度\n","output_size = 5  # 輸出序列的長度\n","hidden_size = 768  # 使用Bert模型的預設隱藏維度\n","\n","# 初始化模型\n","model = SongRecommendationModel(input_size=input_size, output_size=output_size, hidden_size=hidden_size)\n","\n","# 定義損失函數和優化器\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"y3pjE8_z11cQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_data_str = [['6027767fad949f3ca5e772df04924949', '041547bddb0a3e730f32db84c65868ca',\n","               '041547bddb0a3e730f32db84c65868ca', '041547bddb0a3e730f32db84c65868ca',\n","               '8b32f88104ecf859be934d9b45f30cd1', 'e4a125e3163e4c1bd40060614c79bd53',\n","               '8b32f88104ecf859be934d9b45f30cd1', '5ef6718f4517d2d3c316fc45226f41dc',\n","               'e4a125e3163e4c1bd40060614c79bd53', '041547bddb0a3e730f32db84c65868ca',\n","               'e7efab54028017e35a35d1b1637e210c', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","               '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","               '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","               'a97177f0f37a2bae91d8e67831949392', '6027767fad949f3ca5e772df04924949',\n","               '6027767fad949f3ca5e772df04924949', '6027767fad949f3ca5e772df04924949'],\n","              ['883d4ffa999d2f7c8f5293d85112da49', '883d4ffa999d2f7c8f5293d85112da49',\n","               '883d4ffa999d2f7c8f5293d85112da49', 'ecfed150865a7129690805286222656d',\n","               'd36c6cf30154e18e6c972704206d6b1e', 'd36c6cf30154e18e6c972704206d6b1e',\n","               'c7170f4c6488a8f9013f0e4eadf9b385', 'c7170f4c6488a8f9013f0e4eadf9b385',\n","               '940d87a98fef6e456a3f59ecd7e88f63', '883d4ffa999d2f7c8f5293d85112da49',\n","               'f6407930f4a8e921df43911dad3847a3', '4917c1184063708092051859415be029',\n","               '3419b303ba51124a091cde496c6a0c16', 'f57c28ff61e365a82c7a00267d21c96e',\n","               '0d488acd5aa820a96e84f9488f03e335', '807653562fa6eb36cf75dee0279fb124',\n","               '33441a5f6fb494f0d0021f2585c91305', 'fb9b6b981cc1996542d5d81d47b459af',\n","               '65719c6edaa80d0880940c0e20c5e499', '7c4bd89cc6d7c6c91a38d58c2808b1b9']]\n","input_data_int = [[song_id_mapping[song_id] for song_id in row] for row in input_data_str]\n","\n","# 將整數標識符轉換為PyTorch張量\n","input_tensor = torch.tensor(input_data_int, dtype=torch.long)\n","\n","# 使用模型進行預測\n","with torch.no_grad():\n","    model.eval()\n","    predictions = model(input_tensor)\n","\n","# 輸出預測結果\n","print(\"Predictions:\")\n","print(predictions)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJuIdC-80ULK","executionInfo":{"status":"ok","timestamp":1703069661156,"user_tz":-480,"elapsed":5,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"e6b357fe-7e56-44e6-fb92-99cc8fe65deb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions:\n","tensor([[ 0.1106, -0.0038, -0.1039, -0.0351,  0.1045],\n","        [ 0.1106, -0.0038, -0.1039, -0.0351,  0.1045]])\n"]}]},{"cell_type":"markdown","source":["# Seq2Se2"],"metadata":{"id":"PKanyReIxt3i"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"fgK_XtNNNaRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2SeqEncoder(nn.Module):\n","    def __init__(self,embedding_dim,hidden_size,source_vocab_size):\n","        super(Seq2SeqEncoder,self).__init__()\n","\n","        self.lstm_layer = nn.LSTM(input_size=embedding_dim,\n","                                 hidden_size=hidden_size,\n","                                 batch_first=True)\n","        self.embedding_table = torch.nn.Embedding(source_vocab_size,embedding_dim)\n","\n","    def forward(self,input_ids):\n","        # 这里的ids是多个id，所以会是三维的\n","        input_sequence = self.embedding_table(input_ids) # 3d tensor batch*source_length*embedding_dim\n","        output_states,(final_h,final_c) = self.lstm_layer(input_sequence)\n","\n","        return output_states,final_h\n"],"metadata":{"id":"Qb_s3SP2QIah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2SeqAttentionMechanism(nn.Module):\n","    def __init__(self):\n","        super(Seq2SeqAttentionMechanism,self).__init__()\n","\n","    # 单步执行\n","    def forward(self,decoder_state_t,encoder_states):\n","        bs,source_length,hidden_size = encoder_states.shape\n","\n","        # decoder_state是二维 batch*hidden，需要扩维\n","        decoder_state_t = decoder_state_t.unsqueeze(1)\n","        decoder_state_t =  torch.tile(decoder_state_t,(1,source_length,1))\n","\n","        score = torch.sum(decoder_state_t * encoder_states,dim=-1) # bs*source_length\n","\n","        attn_prob = F.softmax(score,dim=-1) # bs*source_length\n","\n","        context = torch.sum(attn_prob.unsqueeze(-1)*encoder_states,1) # bs*hidden_size\n","\n","        return attn_prob,context\n"],"metadata":{"id":"VXgUvx7KQKdJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2SeqDecoder(nn.Module):\n","    def __init__(self,embedding_dim,hidden_size,num_classes,target_vocab_size,start_id,end_id):\n","        super(Seq2SeqDecoder,self).__init__()\n","\n","        # cell就是单步执行\n","        self.lstm_cell = torch.nn.LSTMCell(embedding_dim,hidden_size)\n","        self.proj_layer = nn.Linear(hidden_size*2,num_classes)\n","        self.attention_mechanism = Seq2SeqAttentionMechanism()\n","        self.num_classes = num_classes\n","        self.embedding_table = torch.nn.Embedding(target_vocab_size,embedding_dim)\n","        # 偏移id\n","        self.start_id = start_id\n","        self.end_id = end_id\n","\n","    # 训练用\n","    def forward(self, shifted_target_ids, encoder_states):\n","        shifted_target = self.embedding_table(shifted_target_ids)\n","\n","        bs, target_length, embedding_dim = shifted_target.shape\n","        bs, source_length, hidden_size = encoder_states.shape\n","\n","        logits = torch.zeros(bs, target_length, self.num_classes)\n","        probs = torch.zeros(bs, target_length, source_length)\n","\n","        for t in range(target_length):\n","            decoder_input_t = shifted_target[:, t, :]\n","            if t == 0:\n","                h_t, c_t = self.lstm_cell(decoder_input_t)\n","            else:\n","                h_t, c_t = self.lstm_cell(decoder_input_t, (h_t, c_t))\n","\n","            attn_prob, context = self.attention_mechanism(h_t, encoder_states)\n","\n","            decoder_output = torch.cat((context, h_t), -1)\n","            logits[:, t, :] = self.proj_layer(decoder_output)\n","            probs[:, t, :] = attn_prob\n","\n","        return probs, logits\n","\n","    def inference(self, encoder_states, num_samples=5, max_sequence_length=5):\n","      # 推理階段\n","      result = []\n","\n","      for _ in range(num_samples):\n","          target_id = torch.tensor([self.start_id])  # 使用tensor包裝起始id\n","          h_t = None\n","          sample_result = []\n","\n","          for _ in range(max_sequence_length):  # 控制生成的序列長度\n","              decoder_input_t = self.embedding_table(target_id)\n","              if h_t is None:\n","                  h_t, c_t = self.lstm_cell(decoder_input_t)\n","              else:\n","                  h_t, c_t = self.lstm_cell(decoder_input_t, (h_t, c_t))\n","\n","              attn_prob, context = self.attention_mechanism(h_t, encoder_states)\n","\n","              decoder_output = torch.cat((context, h_t), -1)\n","              logits = self.proj_layer(decoder_output)\n","\n","              # 上一刻預測的，作為下一時刻的輸入\n","              # 基於機率選擇，而不是使用argmax\n","              prob_dist = F.softmax(logits, dim=-1)\n","              target_id = torch.multinomial(prob_dist, 1).squeeze(1)\n","\n","              sample_result.append(vocabulary.index2word[target_id.item()])  # 使用item()獲取Python值\n","\n","              if torch.any(target_id == self.end_id):\n","                  print('stop decoding')\n","                  break\n","\n","          result.append(sample_result)\n","\n","      return result\n"],"metadata":{"id":"2z-AMkcLQNL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self,embedding_dim,hidden_size,num_classes,\n","                source_vocab_size,target_vocab_size,start_id,end_id):\n","        super(Model,self).__init__()\n","\n","        self.encoder = Seq2SeqEncoder(embedding_dim,hidden_size,source_vocab_size)\n","\n","        self.decoder = Seq2SeqDecoder(embedding_dim,hidden_size,num_classes,\n","                                     target_vocab_size,start_id,end_id)\n","\n","    def forward(self,inut_sequence_ids,shifted_target_ids):\n","\n","        encoder_states,final_h = self.encoder(input_sequence_ids)\n","\n","        probs,logits = self.decoder(shifted_target_ids,encoder_states)\n","\n","        return probs,logits\n","    def ifer(self):\n","        pass\n"],"metadata":{"id":"t7gRauLpQPGI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Vocabulary:\n","    def __init__(self):\n","        self.word2index = {}\n","        self.index2word = {}\n","        self.next_index = 0\n","\n","    def add_word(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.next_index\n","            self.index2word[self.next_index] = word\n","            self.next_index += 1\n","\n","    def sequence_to_indices(self, sequence):\n","        return [self.word2index[word] for word in sequence]\n","\n","    def indices_to_sequence(self, indices):\n","        return [self.index2word[index] for index in indices]"],"metadata":{"id":"YK4QrstkAT51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["A = [['6027767fad949f3ca5e772df04924949','041547bddb0a3e730f32db84c65868ca',\n","  '041547bddb0a3e730f32db84c65868ca', '041547bddb0a3e730f32db84c65868ca',\n","  '8b32f88104ecf859be934d9b45f30cd1', 'e4a125e3163e4c1bd40060614c79bd53',\n","  '8b32f88104ecf859be934d9b45f30cd1', '5ef6718f4517d2d3c316fc45226f41dc',\n","  'e4a125e3163e4c1bd40060614c79bd53', '041547bddb0a3e730f32db84c65868ca',\n","  'e7efab54028017e35a35d1b1637e210c', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","  '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","  '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","  'a97177f0f37a2bae91d8e67831949392', '6027767fad949f3ca5e772df04924949',\n","  '6027767fad949f3ca5e772df04924949', '6027767fad949f3ca5e772df04924949'],['6027767fad949f3ca5e772df04924949','041547bddb0a3e730f32db84c65868ca',\n","  '041547bddb0a3e730f32db84c65868ca', '041547bddb0a3e730f32db84c65868ca',\n","  '8b32f88104ecf859be934d9b45f30cd1', 'e4a125e3163e4c1bd40060614c79bd53',\n","  '8b32f88104ecf859be934d9b45f30cd1', '5ef6718f4517d2d3c316fc45226f41dc',\n","  'e4a125e3163e4c1bd40060614c79bd53', '041547bddb0a3e730f32db84c65868ca',\n","  'e7efab54028017e35a35d1b1637e210c', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","  '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","  '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7',\n","  'a97177f0f37a2bae91d8e67831949392', '6027767fad949f3ca5e772df04924949',\n","  '6027767fad949f3ca5e772df04924949', '6027767fad949f3ca5e772df04924949']]\n","\n","B = [['75c2aa348888f982d85e3f870e6ba5b2', '0cab8863e5440551c7b37e59635ec18e',\n","  '4d5aceee5c9731151ca69f0946ffa71f', '929b07d69451684f4f0f6e3bcc2a62d6',\n","  '12ae4e616d3e5c7bd53ec771797f596b'],['75c2aa348888f982d85e3f870e6ba5b2', '0cab8863e5440551c7b37e59635ec18e',\n","  '4d5aceee5c9731151ca69f0946ffa71f', '929b07d69451684f4f0f6e3bcc2a62d6',\n","  '12ae4e616d3e5c7bd53ec771797f596b']]\n","\n","# 示例用法\n","vocabulary = Vocabulary()\n","\n","# 建立词汇表\n","for word_list in A:\n","  for word in word_list:\n","    vocabulary.add_word(word)\n","for word_list in B:\n","  for word in word_list:\n","    vocabulary.add_word(word)"],"metadata":{"id":"bpKrK2dLAI41"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_sequence_indices = []\n","for word_list in A:\n","  a = vocabulary.sequence_to_indices(word_list)\n","  input_sequence_indices.append(a)\n","\n","target_sequence_indices = []\n","for word_list in B:\n","  b = vocabulary.sequence_to_indices(word_list)\n","  target_sequence_indices.append(b)\n","\n","# 转换为 PyTorch tensors\n","input_tensor = torch.tensor(input_sequence_indices).to(torch.int32)\n","target_tensor = torch.tensor(target_sequence_indices).to(torch.int32)\n","\n","target_ids = torch.cat((target_tensor,end_id*torch.ones(bs,1)),dim=1).to(torch.int32)"],"metadata":{"id":"v__tCtcTAq93","executionInfo":{"status":"error","timestamp":1703063883844,"user_tz":-480,"elapsed":331,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"colab":{"base_uri":"https://localhost:8080/","height":212},"outputId":"8e2148bf-a543-483d-a5ae-c70f5bf96ce4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-86-0df4407c47f3>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_sequence_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtarget_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_id\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2 but got size 1 for tensor number 1 in the list."]}]},{"cell_type":"code","source":["import torch\n","\n","# 定义模型和数据\n","source_length = 20\n","embedding_dim = 8\n","hidden_size = 16\n","num_classes = 10\n","bs = 1  # 这里设置为1，因为推断是针对单个序列的\n","start_id = end_id = 0\n","source_vocab_size = 100\n","target_vocab_size = 100\n","\n","input_sequence_ids = torch.randint(source_vocab_size, size=(bs, source_length)).to(torch.int32)\n","\n","# 创建模型\n","model = Model(embedding_dim, hidden_size, num_classes, source_vocab_size, target_vocab_size, start_id, end_id)\n","\n","# 获取encoder_states，这将用于解码器的推断\n","encoder_states, final_h = model.encoder(input_sequence_ids)\n","\n","# 使用推断方法生成序列\n","predicted_sequences  = model.decoder.inference(encoder_states)\n","\n","# 打印生成的序列\n","(predicted_sequences)\n"],"metadata":{"id":"y2Ozvmh8E5EO","executionInfo":{"status":"ok","timestamp":1703063887337,"user_tz":-480,"elapsed":447,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"ea4b2c39-9ec7-447e-877e-5f3025877a4e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["stop decoding\n","stop decoding\n","stop decoding\n"]},{"output_type":"execute_result","data":{"text/plain":["[['5ef6718f4517d2d3c316fc45226f41dc',\n","  'e4a125e3163e4c1bd40060614c79bd53',\n","  '6027767fad949f3ca5e772df04924949'],\n"," ['75c2aa348888f982d85e3f870e6ba5b2', '6027767fad949f3ca5e772df04924949'],\n"," ['a97177f0f37a2bae91d8e67831949392',\n","  '0cab8863e5440551c7b37e59635ec18e',\n","  '5ef6718f4517d2d3c316fc45226f41dc',\n","  '6027767fad949f3ca5e772df04924949'],\n"," ['e4a125e3163e4c1bd40060614c79bd53',\n","  'e4a125e3163e4c1bd40060614c79bd53',\n","  '75c2aa348888f982d85e3f870e6ba5b2',\n","  '0cab8863e5440551c7b37e59635ec18e',\n","  'a97177f0f37a2bae91d8e67831949392'],\n"," ['041547bddb0a3e730f32db84c65868ca',\n","  '75c2aa348888f982d85e3f870e6ba5b2',\n","  'e7efab54028017e35a35d1b1637e210c',\n","  'e7efab54028017e35a35d1b1637e210c',\n","  '3f8e8cbe4b5d55f07ba4c7ddfab624b7']]"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["source_length = 20\n","target_length = 5\n","embedding_dim = 8\n","hidden_size = 16\n","num_classes = 10\n","bs = 2\n","start_id = end_id = 0\n","source_vocab_size = 100\n","target_vocab_size = 100\n","\n","input_sequence_ids = torch.randint(source_vocab_size,size=(bs,source_length)).to(torch.int32)\n","\n","target_ids = torch.randint(target_vocab_size,size=(bs,target_length))\n","target_ids = torch.cat((target_ids,end_id*torch.ones(bs,1)),dim=1).to(torch.int32)\n","\n","shifted_target_ids = torch.cat((start_id*torch.ones(bs,1),target_ids[:,1:]),dim=1).to(torch.int32)\n","\n","model = Model(embedding_dim,hidden_size,num_classes,source_vocab_size,target_vocab_size,start_id,end_id)\n","probs,logits = model(input_sequence_ids,shifted_target_ids)"],"metadata":{"id":"2rNEEj-vBMRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_8XOfOMW6dx","executionInfo":{"status":"ok","timestamp":1703062148460,"user_tz":-480,"elapsed":317,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"6d23ca8c-61f1-492c-dc22-b058e491528e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0.0487, 0.0471, 0.0486, 0.0494, 0.0499, 0.0486, 0.0494, 0.0497,\n","          0.0496, 0.0496, 0.0515, 0.0484, 0.0495, 0.0497, 0.0501, 0.0522,\n","          0.0517, 0.0526, 0.0512, 0.0524],\n","         [0.0448, 0.0450, 0.0489, 0.0531, 0.0518, 0.0479, 0.0507, 0.0502,\n","          0.0483, 0.0481, 0.0534, 0.0483, 0.0514, 0.0512, 0.0527, 0.0520,\n","          0.0508, 0.0514, 0.0496, 0.0506],\n","         [0.0434, 0.0438, 0.0475, 0.0533, 0.0475, 0.0468, 0.0511, 0.0494,\n","          0.0485, 0.0482, 0.0537, 0.0490, 0.0525, 0.0512, 0.0524, 0.0533,\n","          0.0491, 0.0543, 0.0510, 0.0539],\n","         [0.0464, 0.0461, 0.0466, 0.0499, 0.0473, 0.0480, 0.0491, 0.0507,\n","          0.0470, 0.0490, 0.0526, 0.0500, 0.0511, 0.0503, 0.0479, 0.0522,\n","          0.0528, 0.0552, 0.0530, 0.0550],\n","         [0.0498, 0.0482, 0.0501, 0.0529, 0.0583, 0.0520, 0.0520, 0.0508,\n","          0.0448, 0.0476, 0.0527, 0.0467, 0.0517, 0.0503, 0.0497, 0.0481,\n","          0.0538, 0.0482, 0.0467, 0.0457],\n","         [0.0488, 0.0469, 0.0487, 0.0505, 0.0524, 0.0494, 0.0503, 0.0502,\n","          0.0472, 0.0485, 0.0522, 0.0475, 0.0502, 0.0498, 0.0496, 0.0516,\n","          0.0533, 0.0521, 0.0502, 0.0507]],\n","\n","        [[0.0479, 0.0478, 0.0484, 0.0503, 0.0516, 0.0515, 0.0504, 0.0506,\n","          0.0504, 0.0478, 0.0484, 0.0491, 0.0501, 0.0497, 0.0518, 0.0518,\n","          0.0501, 0.0513, 0.0514, 0.0494],\n","         [0.0459, 0.0476, 0.0483, 0.0497, 0.0511, 0.0511, 0.0501, 0.0526,\n","          0.0531, 0.0485, 0.0474, 0.0472, 0.0484, 0.0497, 0.0525, 0.0516,\n","          0.0490, 0.0511, 0.0534, 0.0519],\n","         [0.0458, 0.0468, 0.0502, 0.0523, 0.0511, 0.0488, 0.0550, 0.0519,\n","          0.0563, 0.0515, 0.0511, 0.0466, 0.0513, 0.0501, 0.0500, 0.0480,\n","          0.0453, 0.0482, 0.0495, 0.0502],\n","         [0.0469, 0.0471, 0.0492, 0.0515, 0.0522, 0.0507, 0.0520, 0.0514,\n","          0.0528, 0.0488, 0.0491, 0.0482, 0.0509, 0.0493, 0.0515, 0.0508,\n","          0.0481, 0.0503, 0.0505, 0.0487],\n","         [0.0473, 0.0465, 0.0502, 0.0526, 0.0506, 0.0470, 0.0539, 0.0518,\n","          0.0567, 0.0530, 0.0528, 0.0488, 0.0529, 0.0502, 0.0488, 0.0481,\n","          0.0450, 0.0483, 0.0473, 0.0482],\n","         [0.0474, 0.0468, 0.0492, 0.0512, 0.0519, 0.0502, 0.0515, 0.0513,\n","          0.0528, 0.0494, 0.0496, 0.0491, 0.0514, 0.0495, 0.0511, 0.0507,\n","          0.0483, 0.0506, 0.0497, 0.0483]]], grad_fn=<CopySlices>)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["shifted_target_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zz5lgBFVW4Mv","executionInfo":{"status":"ok","timestamp":1703061195104,"user_tz":-480,"elapsed":4,"user":{"displayName":"林于喬","userId":"09001906669943106509"}},"outputId":"5a2ef397-e8d5-4310-b8b7-2c5201a4023b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0, 29, 68, 33,  0],\n","        [ 0, 43, 14, 83,  0]], dtype=torch.int32)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# Inference\n","with torch.no_grad():\n","    # Generate predictions using the inference method\n","    predicted_ids = model.decoder.inference(model.encoder(input_sequence_ids)[0])\n","\n","    # Print the predicted sequence\n","    print(\"Predicted Sequence:\")\n","    for i in range(bs):\n","        predicted_sequence = [int(predicted_ids[t, i].item()) for t in range(predicted_ids.size(0))]\n","        print(predicted_sequence)"],"metadata":{"id":"-IxnRi4hmOzo","executionInfo":{"status":"error","timestamp":1703055267998,"user_tz":-480,"elapsed":7,"user":{"displayName":"","userId":""}},"outputId":"ecfc94f1-df3d-4dbe-9510-98cba553b11b","colab":{"base_uri":"https://localhost:8080/","height":620}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Context size: torch.Size([2, 16])\n","h_t_repeated size: torch.Size([2, 16])\n","tensor([[-0.0400,  0.1259, -0.0308,  0.1001, -0.0791,  0.0943,  0.0840, -0.0201,\n","         -0.0472, -0.0126, -0.0988, -0.0012,  0.1006, -0.0197, -0.0052, -0.0032,\n","          0.0161, -0.0260,  0.1349,  0.1316,  0.0119,  0.0291,  0.0690,  0.0301,\n","         -0.1018, -0.1098,  0.0258, -0.0464,  0.0350,  0.0136, -0.0012, -0.0703],\n","        [-0.0669,  0.1080,  0.0431,  0.0950, -0.0271,  0.1027, -0.0144, -0.0497,\n","          0.0032,  0.0203, -0.0224, -0.0158,  0.1251,  0.0314, -0.0392, -0.0872,\n","          0.0161, -0.0260,  0.1349,  0.1316,  0.0119,  0.0291,  0.0690,  0.0301,\n","         -0.1018, -0.1098,  0.0258, -0.0464,  0.0350,  0.0136, -0.0012, -0.0703]])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-73-9e0cfec72945>:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  target_id = torch.tensor(target_id, dtype=torch.long)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-76-8e728682af7c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Generate predictions using the inference method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredicted_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Print the predicted sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-73-9e0cfec72945>\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, encoder_states, max_target_length)\u001b[0m\n\u001b[1;32m     49\u001b[0m               \u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m               \u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           \u001b[0mattn_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mechanism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         ret = _VF.lstm_cell(\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input batch size 2 doesn't match hidden0 batch size 1"]}]},{"cell_type":"code","source":["model.encoder(input_sequence_ids)[0]"],"metadata":{"id":"WSJ4C147qK5K","executionInfo":{"status":"ok","timestamp":1703049476188,"user_tz":-480,"elapsed":515,"user":{"displayName":"","userId":""}},"outputId":"09e6af5e-7b9e-4211-8fd2-7a91c038c7d6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-1.4693e-01,  7.9924e-02, -8.0531e-02, -2.7915e-02,  2.7785e-02,\n","           1.3915e-02, -4.1421e-02,  8.9855e-02,  4.0514e-02,  7.4672e-02,\n","           6.3039e-02, -3.7883e-02, -5.7570e-02,  5.6767e-02,  8.1288e-02,\n","          -1.0501e-01],\n","         [-1.9930e-01,  9.2346e-02, -4.6385e-02,  1.1414e-01, -1.7856e-01,\n","          -7.5722e-02, -9.5991e-02, -2.4275e-02,  6.8016e-02,  5.2614e-02,\n","          -1.7428e-01, -2.4964e-02,  4.4947e-02,  1.1409e-01, -4.3466e-02,\n","          -2.2042e-01],\n","         [-1.9896e-01,  1.3815e-01,  4.1449e-02, -4.1453e-02,  2.3651e-03,\n","          -5.1864e-02, -4.8640e-02,  1.5867e-01,  1.1019e-01, -7.7386e-02,\n","          -2.4774e-02, -7.5502e-02, -8.1692e-02,  1.0810e-01,  2.5605e-03,\n","          -4.3216e-02],\n","         [-2.0138e-01,  2.2007e-01,  7.2002e-02, -8.4817e-02,  5.3292e-03,\n","          -1.4397e-01, -6.4865e-02,  1.7637e-01,  7.9066e-02,  7.1616e-02,\n","           3.0461e-02, -2.8392e-02, -1.2075e-01,  1.3214e-01,  3.7748e-02,\n","          -1.7797e-01],\n","         [-1.6918e-01,  2.0907e-01,  1.6319e-01, -1.5479e-01,  4.3499e-02,\n","          -2.9236e-01, -1.0020e-01,  2.2691e-01,  4.3352e-02,  1.0828e-01,\n","           9.9792e-02, -2.7223e-02, -1.9801e-01,  1.0914e-01,  2.8534e-02,\n","          -2.4202e-01],\n","         [-8.7117e-02, -8.9409e-02,  2.8181e-01, -1.7312e-01, -1.8689e-01,\n","          -3.0926e-01, -7.3914e-02,  1.9529e-01,  1.4445e-01,  1.6603e-01,\n","          -3.8148e-02,  1.1431e-01, -1.7984e-01, -1.8673e-01,  1.1367e-01,\n","          -3.7032e-01],\n","         [-1.1850e-01,  4.0292e-02,  2.5305e-01, -1.1914e-01, -1.1181e-01,\n","          -3.3751e-01, -1.1386e-01,  2.4423e-01,  1.2111e-01, -6.0129e-02,\n","          -1.5334e-01, -6.3400e-02, -9.0304e-02,  8.3231e-02,  8.1101e-02,\n","          -2.5797e-01],\n","         [-2.5094e-01,  6.9392e-02, -1.2283e-01,  7.7334e-02, -8.3055e-02,\n","          -5.2653e-02, -6.3483e-02,  1.2340e-01,  1.2503e-01,  5.4959e-02,\n","          -2.6907e-01, -6.6808e-02, -4.7062e-01,  7.8642e-02, -4.8958e-02,\n","          -2.6567e-01],\n","         [-2.2285e-01,  1.3429e-01, -6.7422e-02,  7.6442e-02, -2.1122e-01,\n","          -1.1826e-01, -7.5494e-02, -7.1115e-03,  1.8140e-01,  1.7807e-01,\n","          -2.9690e-01,  3.1913e-03, -2.3019e-01,  2.1271e-01, -4.3067e-02,\n","          -3.0209e-01],\n","         [-2.2356e-01,  6.4749e-02,  1.0672e-02,  1.5982e-04, -2.2166e-01,\n","          -1.4176e-01, -6.7558e-02, -5.7001e-03,  9.6759e-02,  4.7811e-02,\n","          -2.6897e-01, -1.1699e-02,  7.1030e-02,  1.3275e-01, -3.8322e-02,\n","          -1.5817e-01],\n","         [-1.4915e-01,  9.9509e-02,  1.5347e-01, -8.9471e-02, -1.1218e-01,\n","          -2.7273e-01, -4.2667e-02,  2.0594e-01,  2.7219e-01,  9.7867e-02,\n","          -2.7551e-01, -5.2974e-02, -1.6084e-01,  1.7464e-01,  2.6848e-02,\n","          -3.1370e-01],\n","         [-1.8741e-01,  3.0088e-02,  8.1619e-02, -1.4601e-01, -1.6989e-01,\n","          -8.9286e-02, -2.2200e-02,  1.2791e-01,  2.5105e-01,  1.4712e-01,\n","          -2.4470e-01,  1.8593e-02, -9.5229e-02,  5.7757e-02,  1.4119e-02,\n","          -2.8397e-01],\n","         [-3.1664e-01,  2.0084e-01,  5.1593e-02,  1.6419e-01, -2.7778e-01,\n","          -7.7578e-02,  1.1148e-01, -4.5462e-02,  1.8181e-01,  9.1619e-02,\n","          -1.8199e-01, -5.7162e-02,  6.5895e-02,  1.5100e-01, -4.4997e-02,\n","          -1.1991e-01],\n","         [-3.6619e-01,  2.8227e-01, -1.5422e-01,  1.0206e-01, -1.2253e-01,\n","          -1.9098e-02,  5.4058e-02,  5.6950e-03,  1.8288e-01,  1.2476e-01,\n","          -1.8503e-01, -4.5710e-02, -9.7366e-02,  2.1428e-01, -1.0304e-01,\n","          -1.6175e-01],\n","         [-3.8135e-01,  2.7763e-01, -2.2336e-01, -2.0421e-02, -3.7170e-02,\n","           1.0086e-01,  1.3882e-02,  1.0493e-01,  1.2863e-01,  1.0771e-01,\n","          -1.6047e-01, -8.0185e-02, -2.6221e-01,  1.0905e-01, -1.3255e-01,\n","          -1.1993e-01],\n","         [-1.9113e-01,  1.9500e-01, -1.5139e-02, -1.7809e-01, -7.6149e-03,\n","          -9.0834e-02, -1.3050e-01,  1.1557e-01,  2.9733e-02, -7.6874e-02,\n","          -1.9349e-01, -2.3908e-01, -2.9506e-02,  1.5460e-01, -1.4470e-01,\n","          -7.0136e-02],\n","         [-2.9692e-01,  9.7354e-02, -4.3351e-02, -2.0141e-01,  6.6554e-02,\n","           4.8151e-02, -9.4025e-02,  1.2685e-01, -2.2182e-02,  7.5910e-02,\n","          -5.0924e-02, -6.2350e-02, -4.1724e-02,  7.7437e-02, -1.3722e-01,\n","          -4.7406e-02],\n","         [-3.1186e-01,  1.4036e-01, -1.0209e-01, -1.4913e-01,  7.7115e-02,\n","           4.3239e-02, -8.3149e-02,  1.7493e-01,  2.9438e-02,  1.0956e-01,\n","           2.1828e-02, -5.9523e-02, -8.1840e-02,  1.2816e-01,  3.6349e-02,\n","          -1.4954e-01],\n","         [-1.9670e-01,  1.0845e-01,  7.0050e-02, -2.3032e-01,  5.5217e-02,\n","          -5.6922e-02, -1.1782e-01,  1.7455e-01, -4.5234e-02,  5.2980e-02,\n","          -3.1293e-02, -1.2491e-01,  2.4336e-02,  5.7524e-02,  3.4861e-02,\n","          -3.8293e-02],\n","         [-2.3969e-01,  9.2364e-02,  1.1707e-01, -1.7605e-01, -4.0161e-02,\n","          -1.6645e-01, -1.4943e-01,  1.4235e-01, -7.0745e-03,  9.2344e-03,\n","          -8.0326e-02, -1.1499e-01, -3.3141e-02,  5.9319e-02, -5.3590e-02,\n","          -8.3355e-02]],\n","\n","        [[-2.0666e-01,  8.7889e-02, -2.0753e-01,  4.0375e-02,  8.1340e-03,\n","           8.0140e-02, -2.1527e-02,  2.6208e-02,  9.1744e-02,  5.5385e-02,\n","          -2.9241e-02, -7.5065e-02, -1.4251e-01,  8.9047e-02, -1.0569e-01,\n","          -5.0708e-02],\n","         [-3.1706e-01,  1.3960e-01, -3.0936e-01,  4.1734e-02,  2.4949e-02,\n","           1.0988e-01, -4.0248e-02,  4.7011e-02,  1.4209e-01,  9.0750e-02,\n","          -4.5594e-02, -1.1719e-01, -2.1238e-01,  1.3705e-01, -1.4801e-01,\n","          -9.6371e-02],\n","         [-2.0132e-01,  1.7121e-01, -1.3349e-01, -9.0749e-02, -1.0150e-02,\n","           5.0129e-02,  2.3857e-03,  1.2077e-01,  1.9907e-01,  1.7885e-01,\n","          -6.9487e-02, -1.3826e-01, -9.9009e-02,  1.2751e-01,  5.1488e-03,\n","          -1.4691e-01],\n","         [-3.2456e-01,  2.5213e-01, -2.2058e-01, -6.7899e-02,  3.6294e-02,\n","           1.4624e-01, -4.6432e-03,  1.5356e-01,  1.1634e-01,  9.5244e-02,\n","          -4.6102e-02, -1.0103e-01, -2.5504e-01,  7.0275e-02, -9.0287e-02,\n","          -8.7441e-02],\n","         [-2.9032e-01,  2.7345e-01, -1.2685e-01, -7.8772e-02,  3.5799e-02,\n","           7.5784e-02,  2.7826e-02,  2.1265e-01,  2.3838e-01,  1.7298e-01,\n","           3.4035e-02, -3.2285e-02, -2.5807e-01,  1.1472e-01,  2.4628e-02,\n","          -1.7679e-01],\n","         [-2.8447e-01,  3.5350e-01,  2.4307e-02, -1.7329e-01, -1.0470e-01,\n","          -9.6065e-02,  6.4376e-02,  1.4166e-01,  6.1925e-02,  1.8515e-01,\n","          -5.5508e-02, -9.2393e-02, -3.3160e-02,  1.7148e-01, -9.0523e-02,\n","          -9.8918e-02],\n","         [-2.6767e-01,  1.3735e-01,  2.8515e-02, -1.8656e-01, -1.6644e-01,\n","          -1.0334e-01, -2.6290e-02,  4.0704e-02,  8.5271e-03,  3.1327e-02,\n","          -1.8210e-01, -9.1089e-02,  1.3308e-01,  1.1944e-01, -7.4075e-02,\n","          -5.7571e-02],\n","         [-2.2296e-01,  1.2568e-01, -2.4215e-03, -1.5871e-01, -1.1033e-02,\n","          -1.7120e-01, -1.4230e-01,  1.0866e-01,  6.2579e-03, -4.6566e-02,\n","          -1.5174e-01, -1.3460e-01,  8.8101e-02,  2.0047e-01,  2.7527e-02,\n","          -1.5694e-01],\n","         [-3.0770e-01,  3.8214e-02, -2.3993e-02, -1.9276e-01,  5.7829e-02,\n","          -3.0717e-02, -9.1336e-02,  1.2173e-01, -3.8229e-02,  7.5343e-02,\n","          -2.1276e-02, -3.0411e-02,  5.7690e-03,  6.8052e-02,  5.7279e-03,\n","          -4.8695e-02],\n","         [-3.8041e-01,  7.3449e-02, -8.1258e-02, -1.6719e-01,  7.7289e-02,\n","           5.5234e-02, -4.9691e-02,  1.1904e-01, -1.7044e-03,  1.2173e-01,\n","           3.5033e-02,  2.6318e-03, -2.4501e-02,  5.6853e-02,  4.7616e-02,\n","          -1.2806e-01],\n","         [-2.4242e-01,  1.0536e-01,  4.7184e-02, -2.3917e-01,  4.0073e-02,\n","          -1.2503e-01, -1.0911e-01,  1.4852e-01, -1.0767e-01,  6.4698e-02,\n","          -2.6314e-02, -6.8171e-02,  4.3755e-02,  1.0270e-01,  2.4814e-02,\n","          -8.1317e-02],\n","         [-2.3816e-01,  1.0293e-01,  2.1403e-02, -2.2580e-01,  5.6350e-02,\n","          -2.8764e-02, -1.0375e-01,  1.7119e-01, -1.7882e-01,  1.0078e-01,\n","          -2.6507e-02, -1.1936e-01,  5.6124e-02,  1.0757e-01,  4.0215e-02,\n","          -7.0451e-02],\n","         [-2.2854e-01,  1.2552e-01, -3.5326e-03, -1.3743e-01, -1.1638e-02,\n","          -1.6976e-01, -1.3864e-01,  9.6523e-02, -1.3272e-01,  1.1155e-01,\n","          -5.0453e-02,  1.0464e-02,  9.2411e-02,  1.6943e-01,  6.2060e-02,\n","          -2.1411e-01],\n","         [-1.7981e-01, -6.1192e-02,  2.9789e-02, -1.9638e-01, -1.7124e-02,\n","          -1.4004e-01, -1.9350e-01,  1.1492e-01, -4.8473e-02,  1.0741e-01,\n","          -1.3284e-01, -4.0044e-02,  9.7232e-02,  8.7871e-02, -2.8909e-02,\n","          -1.8486e-01],\n","         [-1.6320e-01,  9.1541e-02,  3.7445e-02, -9.3200e-02, -2.1562e-02,\n","          -3.2891e-01, -8.8113e-02,  2.3247e-01, -3.0960e-02,  9.8446e-02,\n","          -4.7437e-02, -1.9917e-02,  1.8372e-02,  2.3580e-01,  6.9546e-02,\n","          -2.2255e-01],\n","         [-8.8959e-02,  1.1671e-01,  1.3623e-01, -8.7947e-02, -1.6814e-01,\n","          -4.7671e-01, -1.1259e-01,  1.6151e-01, -8.1379e-02, -1.1041e-01,\n","          -1.7017e-01, -3.2666e-02,  8.2813e-02,  1.6549e-01,  9.4764e-02,\n","          -2.3182e-01],\n","         [-2.1987e-01,  2.1932e-01,  1.1154e-01, -2.4090e-02, -1.3019e-01,\n","          -2.4280e-01,  6.8097e-02,  1.3955e-01, -1.6019e-01, -1.0022e-02,\n","          -1.4011e-01, -6.9930e-02,  8.8076e-02,  2.8998e-01,  1.2556e-01,\n","          -9.6795e-02],\n","         [-2.1154e-01,  1.2942e-01,  4.3397e-02, -8.0635e-02, -6.6066e-02,\n","          -2.1412e-01, -4.7930e-02,  1.4104e-01,  3.6056e-02,  1.0365e-01,\n","          -2.4158e-01, -2.5519e-02,  1.0912e-02,  1.9985e-01,  1.1067e-01,\n","          -2.9911e-01],\n","         [-1.4336e-01,  1.0308e-01,  1.4201e-01, -1.4190e-01, -1.1856e-01,\n","          -2.5743e-01,  3.6922e-02,  1.7723e-01,  1.1082e-01,  1.9097e-01,\n","          -5.3209e-02,  1.3279e-01,  1.8372e-02, -3.3703e-02,  3.0516e-01,\n","          -2.9270e-01],\n","         [-1.0194e-01,  1.0832e-01,  1.6810e-01, -1.3825e-01, -2.3016e-01,\n","          -4.6886e-01,  4.5150e-03,  1.6086e-01, -1.4885e-02, -4.3448e-02,\n","          -1.7362e-01,  6.0145e-02,  7.7338e-02,  1.1927e-01,  1.5779e-01,\n","          -2.2361e-01]]], grad_fn=<TransposeBackward0>)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["source_length = 20\n","target_length = 5\n","embedding_dim = 8\n","hidden_size = 16\n","num_classes = 20\n","bs = 2\n","start_id = end_id = 0\n","source_vocab_size = 100\n","target_vocab_size = 100\n","\n","input_sequence_ids = torch.randint(source_vocab_size,size=(bs,source_length)).to(torch.int64)\n","\n","target_ids = torch.randint(target_vocab_size,size=(bs,target_length))\n","target_ids = torch.cat((target_tensor,end_id*torch.ones(bs,1)),dim=1).to(torch.int64)\n","\n","shifted_target_ids = torch.cat((start_id*torch.ones(bs,1),target_ids[:,1:]),dim=1).to(torch.int64)\n","\n","model = Model(embedding_dim,hidden_size,num_classes,source_vocab_size,target_vocab_size,start_id,end_id)\n","probs,logits = model(input_tensor,shifted_target_ids)\n","print(probs.shape)\n","print(logits.shape)"],"metadata":{"id":"Aj032enjQQV3","executionInfo":{"status":"ok","timestamp":1703049068639,"user_tz":-480,"elapsed":7,"user":{"displayName":"","userId":""}},"outputId":"600df14b-6559-4273-fa48-83884d336599","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 6, 20])\n","torch.Size([2, 6, 20])\n"]}]},{"cell_type":"code","source":["\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    # Forward pass\n","    probs, logits = model(input_sequence_ids, shifted_target_ids)\n","\n","    # Reshape logits for loss calculation\n","    logits_flat = logits.view(-1, num_classes)\n","    shifted_target_ids_flat = shifted_target_ids.view(-1).long()\n","\n","    # Compute the loss\n","    loss = criterion(logits_flat, shifted_target_ids_flat)\n","\n","    # Backward pass and optimization\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Print the loss every 10 epochs\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","\n"],"metadata":{"id":"30Y3COpLhgrB","executionInfo":{"status":"ok","timestamp":1703049075181,"user_tz":-480,"elapsed":1661,"user":{"displayName":"","userId":""}},"outputId":"7cfad1e8-b4b8-4097-c115-5e18357baab2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 2.9035\n","Epoch [20/100], Loss: 2.8059\n","Epoch [30/100], Loss: 2.6876\n","Epoch [40/100], Loss: 2.5256\n","Epoch [50/100], Loss: 2.2859\n","Epoch [60/100], Loss: 1.9511\n","Epoch [70/100], Loss: 1.6283\n","Epoch [80/100], Loss: 1.3961\n","Epoch [90/100], Loss: 1.2292\n","Epoch [100/100], Loss: 1.1005\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate\n","\n","# Define the attention layer\n","class BahdanauAttention(tf.keras.layers.Layer):\n","    def __init__(self, units):\n","        super(BahdanauAttention, self).__init__()\n","        self.W1 = Dense(units)\n","        self.W2 = Dense(units)\n","        self.V = Dense(1)\n","\n","    def call(self, query, values):\n","        query_with_time_axis = tf.expand_dims(query, 1)\n","        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n","        attention_weights = tf.nn.softmax(score, axis=1)\n","        context_vector = attention_weights * values\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","        return context_vector, attention_weights\n","\n","# Define the seq2seq model with attention\n","def create_seq2seq_attention_model(input_shape, output_sequence_length):\n","    # Encoder\n","    encoder_inputs = Input(shape=(None,20))\n","    encoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n","    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n","    encoder_states = [state_h, state_c]\n","\n","    # Decoder\n","    decoder_inputs = Input(shape=(None,))\n","    decoder_embedding = Embedding(output_sequence_length, 128)(decoder_inputs)\n","    decoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n","    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","\n","    # Attention mechanism\n","    attention_layer = BahdanauAttention(128)\n","    context_vector, attention_weights = attention_layer(state_h, encoder_outputs)\n","\n","    # Concatenate attention output and decoder LSTM output\n","    decoder_concat = Concatenate(axis=-1)([decoder_outputs, context_vector])\n","\n","    # Dense layer for output\n","    decoder_dense = Dense(output_sequence_length, activation='softmax')\n","    decoder_outputs = decoder_dense(decoder_concat)\n","\n","    # Model\n","    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","    return model\n","\n","\n","input_data = np.array([\n","    ['6027767fad949f3ca5e772df04924949', '041547bddb0a3e730f32db84c65868ca', '041547bddb0a3e730f32db84c65868ca', '041547bddb0a3e730f32db84c65868ca', '8b32f88104ecf859be934d9b45f30cd1', 'e4a125e3163e4c1bd40060614c79bd53', '8b32f88104ecf859be934d9b45f30cd1', '5ef6718f4517d2d3c316fc45226f41dc', 'e4a125e3163e4c1bd40060614c79bd53', '041547bddb0a3e730f32db84c65868ca', 'e7efab54028017e35a35d1b1637e210c', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', 'a97177f0f37a2bae91d8e67831949392', '6027767fad949f3ca5e772df04924949', '6027767fad949f3ca5e772df04924949', '6027767fad949f3ca5e772df04924949'],\n","    ['883d4ffa999d2f7c8f5293d85112da49', '883d4ffa999d2f7c8f5293d85112da49', '883d4ffa999d2f7c8f5293d85112da49', 'ecfed150865a7129690805286222656d', 'd36c6cf30154e18e6c972704206d6b1e', 'd36c6cf30154e18e6c972704206d6b1e', 'c7170f4c6488a8f9013f0e4eadf9b385', 'c7170f4c6488a8f9013f0e4eadf9b385', '940d87a98fef6e456a3f59ecd7e88f63', '883d4ffa999d2f7c8f5293d85112da49', 'f6407930f4a8e921df43911dad3847a3', '4917c1184063708092051859415be029', '3419b303ba51124a091cde496c6a0c16', 'f57c28ff61e365a82c7a00267d21c96e', '0d488acd5aa820a96e84f9488f03e335', '807653562fa6eb36cf75dee0279fb124', '33441a5f6fb494f0d0021f2585c91305', 'fb9b6b981cc1996542d5d81d47b459af', '65719c6edaa80d0880940c0e20c5e499', '7c4bd89cc6d7c6c91a38d58c2808b1b9']\n","])\n","\n","output_data = np.array([\n","    ['75c2aa348888f982d85e3f870e6ba5b2', '0cab8863e5440551c7b37e59635ec18e', '4d5aceee5c9731151ca69f0946ffa71f', '929b07d69451684f4f0f6e3bcc2a62d6', '12ae4e616d3e5c7bd53ec771797f596b'],\n","    ['34f1a786e245f2886ab99b0062de906c', 'd8ec0f80ee6b4457f12e74aa469335d6', 'd63dbd5214a39f50100c8d59f1c24d6a', 'c1550c264fb083b3acffe619bd02d75e', '61a3b37f326394081b95196a5eb676b8']\n","])\n","\n","# Tokenize input and output data\n","input_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","input_tokenizer.fit_on_texts(input_data.flatten())\n","input_data_seq = input_tokenizer.texts_to_sequences(input_data.flatten())\n","input_data_seq = np.array(input_data_seq).reshape(input_data.shape)\n","\n","output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","output_tokenizer.fit_on_texts(output_data.flatten())\n","output_data_seq = output_tokenizer.texts_to_sequences(output_data.flatten())\n","output_data_seq = np.array(output_data_seq).reshape(output_data.shape)\n","\n","# Pad sequences\n","input_data_padded = tf.keras.preprocessing.sequence.pad_sequences(input_data_seq, padding='post')\n","output_data_padded = tf.keras.preprocessing.sequence.pad_sequences(output_data_seq, padding='post')\n","\n","\n","\n","# Define model\n","model = create_seq2seq_attention_model(input_data_padded.shape, output_data_padded.shape[1])\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train model\n","model.fit([input_data_padded, output_data_padded[:, :-1]], np.expand_dims(output_data_padded[:, 1:], -1), epochs=50, batch_size=2)\n","\n","# Generate predictions (same as before)\n","sample_input = input_data_padded[0:1]\n","predictions = model.predict([sample_input, np.zeros((sample_input.shape[0], output_data_padded.shape[1]))])\n","\n","# Decode predictions (same as before)\n","decoded_predictions = []\n","for i in range(predictions.shape[0]):\n","    decoded_predictions.append([output_tokenizer.index_word[idx] for idx in np.argmax(predictions[i], axis=1)])\n","\n","print('Sample Input:', input_data[0])\n","print('Predicted Output:', decoded_predictions[0])\n"],"metadata":{"id":"aHceJOmIWsIs","executionInfo":{"status":"error","timestamp":1703037845939,"user_tz":-480,"elapsed":2297,"user":{"displayName":"","userId":""}},"outputId":"fe824465-80ac-4077-a18f-1323da1fac56","colab":{"base_uri":"https://localhost:8080/","height":392}},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-208a65b59b0f>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_seq2seq_attention_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Compile model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-208a65b59b0f>\u001b[0m in \u001b[0;36mcreate_seq2seq_attention_model\u001b[0;34m(input_shape, output_sequence_length)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Concatenate attention output and decoder LSTM output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mdecoder_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Dense layer for output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/merging/concatenate.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshape_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;31m# Get the only rank for the set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, None, 128), (None, 128)]"]}]},{"cell_type":"code","source":["output_data_padded.shape"],"metadata":{"id":"a5FZlXch9EMi","executionInfo":{"status":"ok","timestamp":1703037988276,"user_tz":-480,"elapsed":337,"user":{"displayName":"","userId":""}},"outputId":"ee053699-45e9-4a41-d03c-35d4a70cc504","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 5)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# prompt: input: [['6027767fad949f3ca5e772df04924949' '041547bddb0a3e730f32db84c65868ca'   '041547bddb0a3e730f32db84c65868ca' '041547bddb0a3e730f32db84c65868ca'   '8b32f88104ecf859be934d9b45f30cd1' 'e4a125e3163e4c1bd40060614c79bd53'   '8b32f88104ecf859be934d9b45f30cd1' '5ef6718f4517d2d3c316fc45226f41dc'   'e4a125e3163e4c1bd40060614c79bd53' '041547bddb0a3e730f32db84c65868ca'   'e7efab54028017e35a35d1b1637e210c' '3f8e8cbe4b5d55f07ba4c7ddfab624b7'   '3f8e8cbe4b5d55f07ba4c7ddfab624b7' '3f8e8cbe4b5d55f07ba4c7ddfab624b7'   '3f8e8cbe4b5d55f07ba4c7ddfab624b7' '3f8e8cbe4b5d55f07ba4c7ddfab624b7'   'a97177f0f37a2bae91d8e67831949392' '6027767fad949f3ca5e772df04924949'   '6027767fad949f3ca5e772df04924949' '6027767fad949f3ca5e772df04924949']  ['883d4ffa999d2f7c8f5293d85112da49' '883d4ffa999d2f7c8f5293d85112da49'   '883d4ffa999d2f7c8f5293d85112da49' 'ecfed150865a7129690805286222656d'   'd36c6cf30154e18e6c972704206d6b1e' 'd36c6cf30154e18e6c972704206d6b1e'   'c7170f4c6488a8f9013f0e4eadf9b385' 'c7170f4c6488a8f9013f0e4eadf9b385'   '940d87a98fef6e456a3f59ecd7e88f63' '883d4ffa999d2f7c8f5293d85112da49'   'f6407930f4a8e921df43911dad3847a3' '4917c1184063708092051859415be029'   '3419b303ba51124a091cde496c6a0c16' 'f57c28ff61e365a82c7a00267d21c96e'   '0d488acd5aa820a96e84f9488f03e335' '807653562fa6eb36cf75dee0279fb124'   '33441a5f6fb494f0d0021f2585c91305' 'fb9b6b981cc1996542d5d81d47b459af'   '65719c6edaa80d0880940c0e20c5e499' '7c4bd89cc6d7c6c91a38d58c2808b1b9']]  output: [['75c2aa348888f982d85e3f870e6ba5b2' '0cab8863e5440551c7b37e59635ec18e'   '4d5aceee5c9731151ca69f0946ffa71f' '929b07d69451684f4f0f6e3bcc2a62d6'   '12ae4e616d3e5c7bd53ec771797f596b']  ['34f1a786e245f2886ab99b0062de906c' 'd8ec0f80ee6b4457f12e74aa469335d6'   'd63dbd5214a39f50100c8d59f1c24d6a' 'c1550c264fb083b3acffe619bd02d75e'   '61a3b37f326394081b95196a5eb676b8']]  我想要輸入20首歌的id然後輸出接下來的5首歌id，我有一批這樣的訓練集，範例如上。 給我使用attention的seq2seq模型。輸入跟輸出要符合我給的格式。且5個輸出都要不同。用我給的input做訓練，使用pytorch\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate\n","\n","# Define the encoder and decoder layers\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers):\n","        super().__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","\n","    def forward(self, x):\n","        output, (h, c) = self.lstm(x)\n","        return output, h, c\n","\n","class Decoder(nn.Module):\n","    def __init__(self, hidden_dim, output_dim, num_layers):\n","        super().__init__()\n","        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)\n","        self.linear = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x, h, c):\n","        output, (h, c) = self.lstm(x, (h, c))\n","        output = self.linear(output)\n","        return output, h, c\n","\n","# Define the attention layer\n","class Attention(nn.Module):\n","    def __init__(self, hidden_dim):\n","        super().__init__()\n","        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n","        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.linear3 = nn.Linear(hidden_dim, 1)\n","\n","    def forward(self, query, key, value):\n","        query = self.linear1(query)\n","        key = self.linear2(key)\n","        value = self.linear3(value)\n","        attention = torch.bmm(query, key.transpose(1, 2))\n","        attention = F.softmax(attention, dim=2)\n","        output = torch.bmm(attention, value)\n","        return output\n","\n","# Define the seq2seq model\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, attention):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.attention = attention\n","\n","    def forward(self, x, y):\n","        # Encode the input sequence\n","        output, h, c = self.encoder(x)\n","\n","        # Initialize the hidden state and cell state of the decoder\n","        decoder_h = h\n","        decoder_c = c\n","\n","        # Generate the output sequence\n","        outputs = []\n","        for i in range(y.shape[1]):\n","            # Get the current input to the decoder\n","            y_i = y[:, i, :]\n","\n","            # Compute the attention weights\n","            attention_weights = self.attention(decoder_h, output, output)\n","\n","            # Compute the context vector\n","            context_vector = torch.bmm(attention_weights, output)\n","\n","            # Concatenate the context vector and the current input\n","            x_i = torch.cat((context_vector, y_i), dim=1)\n","\n","            # Decode the input\n","            output, decoder_h, decoder_c = self.decoder(x_i, decoder_h, decoder_c)\n","\n","            # Store the output\n","            outputs.append(output)\n","\n","        return outputs\n","\n","# Create the model\n","encoder = Encoder(input_dim=20, hidden_dim=128, num_layers=2)\n","decoder = Decoder(hidden_dim=128, output_dim=20, num_layers=2)\n","attention = Attention(hidden_dim=128)\n","model = Seq2Seq(encoder, decoder, attention)\n","\n","# Train the model\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","for epoch in range(10):\n","    model.train()\n","    total_loss = 0\n","    for i, (x, y) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        outputs = model(x, y)\n","        loss = criterion(outputs.view(-1, 20), y.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    print(\"Epoch {}: Loss = {}\".format(epoch, total_loss / len(train_loader)))\n","\n","# Evaluate the model\n","model.eval()\n","total_correct = 0\n","for i, (x, y) in enumerate(test_loader):\n","    outputs = model(x, y)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total_correct += (predicted == y).sum().item()\n","print(\"Accuracy = {}\".format(total_correct / len(test_loader)))\n","\n","# Generate predictions\n","model.eval()\n","x = torch.tensor([['6027767fad949f3ca5e772df04924949', '041547bddb0a3e730f32db84c65868ca', '041547bddb0a3e730f32db84c65868ca', '041547bddb0a3e730f32db84c65868ca', '8b32f88104ecf859be934d9b45f30cd1', 'e4a125e3163e4c1bd40060614c79bd53', '8b32f88104ecf859be934d9b45f30cd1', '5ef6718f4517d2d3c316fc45226f41dc', 'e4a125e3163e4c1bd40060614c79bd53', '041547bddb0a3e730f32db84c65868ca', 'e7efab54028017e35a35d1b1637e210c', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', '3f8e8cbe4b5d55f07ba4c7ddfab624b7', 'a97177f0f37a2bae91d8e67831949392', '6027767fad949f3ca5e772df04924949', '6027767fad949f3ca5e772df04924949', '6027767fad949f3ca5e772df04924949']], dtype=torch.long)\n","outputs = model(x)\n","_, predicted = torch.max(outputs.data, 1)\n","print(predicted)\n"],"metadata":{"id":"adow4irLczBN","executionInfo":{"status":"error","timestamp":1702999465123,"user_tz":-480,"elapsed":602,"user":{"displayName":"","userId":""}},"outputId":"90e68f85-50b0-4cb9-c34a-4b01e1635d8d","colab":{"base_uri":"https://localhost:8080/","height":392}},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-4b5ab3790f34>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     43\u001b[0m             if not all(\n\u001b[1;32m     44\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mpg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             ):\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`fused=True` requires all the params to be CUDA, floating point Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvert_frame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from .eval_frame import (\n\u001b[1;32m      5\u001b[0m     \u001b[0massume_constant_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCheckFunctionManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGuardedCode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moutput_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOutputGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreplay_record\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExecutionRecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInstructionTranslator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtorchdynamo_logging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompiledFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompilerFn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbytecode_transformation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_instruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/variables/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariableTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuiltin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnumVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdicts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstDictVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataClassVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDefaultDictVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from .functions import (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/variables/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttrSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdict_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0modict_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/source.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdataclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLocalSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mlocal_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36mdataclass\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[0;31m# We're called as @dataclass without parens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         return _process_class(cls, init, repr, eq, order, unsafe_hash,\n\u001b[0m\u001b[1;32m   1176\u001b[0m                               frozen, match_args, kw_only, slots)\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# Raise an exception if any of our bases are frozen, but we're not.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many_frozen_base\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrozen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             raise TypeError('cannot inherit non-frozen dataclass from a '\n\u001b[0m\u001b[1;32m    986\u001b[0m                             'frozen one')\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot inherit non-frozen dataclass from a frozen one"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[{"file_id":"https://github.com/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb","timestamp":1703059295908}],"collapsed_sections":["5PfxbMB3ekHb","phVPv-2IkrZz","Hk6kR7vMk5Ii","3ez2odk8k7JR","jTMmWamjk-UU","-9Tq4e-8lBHK","OJ1TIzAElEOn","Nq3cVcLdlGBw"]},"widgets":{"application/vnd.jupyter.widget-state+json":{"65bb190eef8c45f1a8616ca053b8a6b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cdd7112ae62435092bb00ea69e275a8","IPY_MODEL_11b1337301344ceda02b06a491c7dbee","IPY_MODEL_c58a4089d7c448e2bcfa085be9530f2c"],"layout":"IPY_MODEL_f7f44bd24bca48138c75052786035b99"}},"7cdd7112ae62435092bb00ea69e275a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a211cae2f6764b86a3cd0ff369a2fcdd","placeholder":"​","style":"IPY_MODEL_e3b67790a8af48a6b57266615f272aa1","value":"tokenizer_config.json: 100%"}},"11b1337301344ceda02b06a491c7dbee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_095c35a72724417f8bbe51b909cf598c","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3232ba7bd4f4a2ab14143b35e27e280","value":28}},"c58a4089d7c448e2bcfa085be9530f2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3338779dc42425980aba5a730b21f34","placeholder":"​","style":"IPY_MODEL_42045bf3f1164473b5d40f7648bc1a48","value":" 28.0/28.0 [00:00&lt;00:00, 896B/s]"}},"f7f44bd24bca48138c75052786035b99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a211cae2f6764b86a3cd0ff369a2fcdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3b67790a8af48a6b57266615f272aa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"095c35a72724417f8bbe51b909cf598c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3232ba7bd4f4a2ab14143b35e27e280":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3338779dc42425980aba5a730b21f34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42045bf3f1164473b5d40f7648bc1a48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ed5ebef5958463a8c9a185f8f08319c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b40b67901d7247fab713b8dd9fc46cca","IPY_MODEL_f3d224d57e7744e19fa9c69eaad8af85","IPY_MODEL_872cb0d6493149828bdf38f2f3b856a0"],"layout":"IPY_MODEL_c155a461a9f94f33b3d215fc8232ea1f"}},"b40b67901d7247fab713b8dd9fc46cca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b04098468dad44f29c4682c948d513a5","placeholder":"​","style":"IPY_MODEL_abc2099ec84444f080319218711f8bd1","value":"vocab.txt: 100%"}},"f3d224d57e7744e19fa9c69eaad8af85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bc1c4f272834b4695962473fbb08bba","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ac6d9a9bd9b4b308d6a555e3be0b735","value":231508}},"872cb0d6493149828bdf38f2f3b856a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64af82e5cbf6429184abc7d7ef231b6c","placeholder":"​","style":"IPY_MODEL_4d19392065484111a860db23d1dbedbc","value":" 232k/232k [00:00&lt;00:00, 6.10MB/s]"}},"c155a461a9f94f33b3d215fc8232ea1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b04098468dad44f29c4682c948d513a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abc2099ec84444f080319218711f8bd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bc1c4f272834b4695962473fbb08bba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ac6d9a9bd9b4b308d6a555e3be0b735":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64af82e5cbf6429184abc7d7ef231b6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d19392065484111a860db23d1dbedbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd272e92df07457c992822957f7988ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52f42d3a1802457c8ff8a4feb1242c60","IPY_MODEL_2e3d3364124944a6bf0c8e25a5db72bc","IPY_MODEL_37a411708b634dbe8f13368acbfed45d"],"layout":"IPY_MODEL_3e96c3390849475cbf35c5fa1c5d1adc"}},"52f42d3a1802457c8ff8a4feb1242c60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d5503abdc684678bb4f96059753db32","placeholder":"​","style":"IPY_MODEL_c84d2f054b0147e39ecdaa6cc4cfe1c7","value":"tokenizer.json: 100%"}},"2e3d3364124944a6bf0c8e25a5db72bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_daa54d651f04424ebfdff8e552cb7c5a","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3d4df9d67c54b02a409a533454800e2","value":466062}},"37a411708b634dbe8f13368acbfed45d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfebc1b57c3c4084945d28003003b4ef","placeholder":"​","style":"IPY_MODEL_2ae1ed7d68064851902a423e9a0b9311","value":" 466k/466k [00:00&lt;00:00, 11.2MB/s]"}},"3e96c3390849475cbf35c5fa1c5d1adc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d5503abdc684678bb4f96059753db32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c84d2f054b0147e39ecdaa6cc4cfe1c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daa54d651f04424ebfdff8e552cb7c5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3d4df9d67c54b02a409a533454800e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bfebc1b57c3c4084945d28003003b4ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ae1ed7d68064851902a423e9a0b9311":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a110a472f2b43ea8d63911c812060d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c60935cc7a2497abaee1023161b921b","IPY_MODEL_4d7080df9fc84255bbcd419532751e23","IPY_MODEL_0b86f4217b7a4b99b6946706f0f9b48c"],"layout":"IPY_MODEL_d536c83edc5248968b1d823f3df67cc1"}},"9c60935cc7a2497abaee1023161b921b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76a19ab2fa474f0db51315c9a2e98a69","placeholder":"​","style":"IPY_MODEL_fe95e0f1d8244a5dab3cf375a6bd455b","value":"config.json: 100%"}},"4d7080df9fc84255bbcd419532751e23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9c8ddcd7783443ab757e1f44d249e30","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cab5a67a9b214ec49c8bc77f7d0a6e24","value":570}},"0b86f4217b7a4b99b6946706f0f9b48c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_806b9b532d2f4423b3ae20c4b7135165","placeholder":"​","style":"IPY_MODEL_9af89377141f4dbbb61d176b4fb13bc1","value":" 570/570 [00:00&lt;00:00, 30.2kB/s]"}},"d536c83edc5248968b1d823f3df67cc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a19ab2fa474f0db51315c9a2e98a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe95e0f1d8244a5dab3cf375a6bd455b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9c8ddcd7783443ab757e1f44d249e30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cab5a67a9b214ec49c8bc77f7d0a6e24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"806b9b532d2f4423b3ae20c4b7135165":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9af89377141f4dbbb61d176b4fb13bc1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bdcd4f1179e4daa90163a62c9e070ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac56e201e95c450ea6ec777122c7e1bc","IPY_MODEL_a9e83dec58004f92b0c19dde50dfb47d","IPY_MODEL_d9b2f2356f9d462fb818ebfadd8d25e7"],"layout":"IPY_MODEL_43abfa238d54420b8ff717e5b82157e3"}},"ac56e201e95c450ea6ec777122c7e1bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2eb21d4147c4503ae79276dcb8b335e","placeholder":"​","style":"IPY_MODEL_1a13b6917a5e401e8515c40c8cef9c77","value":"model.safetensors: 100%"}},"a9e83dec58004f92b0c19dde50dfb47d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca9f90ea67c84a1d9144f5107d121680","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d33f6e09a5e4f55bd7d1d133609269b","value":440449768}},"d9b2f2356f9d462fb818ebfadd8d25e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4286ce0463194c82bdd75d477db6bd65","placeholder":"​","style":"IPY_MODEL_b9359cb5cee3480a9b5e7b8cc9859946","value":" 440M/440M [00:05&lt;00:00, 77.8MB/s]"}},"43abfa238d54420b8ff717e5b82157e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2eb21d4147c4503ae79276dcb8b335e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a13b6917a5e401e8515c40c8cef9c77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca9f90ea67c84a1d9144f5107d121680":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d33f6e09a5e4f55bd7d1d133609269b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4286ce0463194c82bdd75d477db6bd65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9359cb5cee3480a9b5e7b8cc9859946":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}